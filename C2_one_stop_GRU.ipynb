{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1214,"status":"ok","timestamp":1665682942495,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"},"user_tz":-420},"id":"W1KDRJXuDMNj","outputId":"4fa99251-ddcc-49d2-ca93-0a15973a052d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","To: /content/ThaiDepression.zip\n","\r  0% 0.00/41.1k [00:00<?, ?B/s]\r100% 41.1k/41.1k [00:00<00:00, 45.8MB/s]\n","Archive:  /content/ThaiDepression.zip\n","  inflating: ThaiDepression/AHB_01.csv  \n","  inflating: ThaiDepression/AHB_02.csv  \n","  inflating: ThaiDepression/AHB_03.csv  \n","  inflating: ThaiDepression/AHB_04.csv  \n","  inflating: ThaiDepression/AHB_05.csv  \n","  inflating: ThaiDepression/AHB_06.csv  \n","  inflating: ThaiDepression/AHB_07.csv  \n","  inflating: ThaiDepression/AHB_08.csv  \n","  inflating: ThaiDepression/AHB_09.csv  \n","  inflating: ThaiDepression/AHB_10.csv  \n","  inflating: ThaiDepression/AHB_11.csv  \n","  inflating: ThaiDepression/AHB_12.csv  \n","  inflating: ThaiDepression/AHB_13.csv  \n","  inflating: ThaiDepression/All_AHB.csv  \n"]}],"source":["! gdown 1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","! unzip /content/ThaiDepression.zip"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"XY5mr2mxBKNI","executionInfo":{"status":"ok","timestamp":1665682946583,"user_tz":-420,"elapsed":4090,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from numpy import array\n","from math import sqrt\n","from numpy import mean\n","from pandas import DataFrame\n","from pandas import concat\n","from pandas import read_csv\n","from keras.callbacks import EarlyStopping\n","from keras.models import Sequential\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n","from keras.preprocessing import sequence\n","from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GRU, BatchNormalization\n","from pandas import read_csv\n","from keras import Model\n","from keras.layers import Layer\n","import keras.backend as K\n","from keras.layers import Input, SimpleRNN\n","import json\n","import psutil \n","from datetime import datetime, timezone, timedelta"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0xd-eM3VJVz5","executionInfo":{"status":"ok","timestamp":1665682946584,"user_tz":-420,"elapsed":6,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"}}},"outputs":[],"source":["file_list = os.listdir('ThaiDepression')\n","file_list.sort()\n","df_list = []\n","for i in range(14):\n","    df_list.append(pd.read_csv('ThaiDepression/' + file_list[i], index_col=0))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1034,"status":"ok","timestamp":1665682947613,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"},"user_tz":-420},"id":"kMC4i-X-OTDb","outputId":"889f171b-5955-4bd5-a834-988edd53967b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[         Chiang_Rai    Nan  Phayao  Phrae  Chiang_Mai  Mae_Hong_Son  Lampang  \\\n"," 2016-10       10383   5315    4266   4057       15408          2002     9011   \n"," 2016-11       10383   5315    4265   4057       15406          2002     9011   \n"," 2016-12       10382   5315    4265   4057       15404          2002     9011   \n"," 2017-01       10382   5655    4265   4057       15393          2002     9011   \n"," 2017-02       10382   5655    4264   4057       15392          2002     9011   \n"," ...             ...    ...     ...    ...         ...           ...      ...   \n"," 2022-03       25223   9711   10788   7988       47292          6924    17444   \n"," 2022-04       25456   9781   10932   8095       48020          7004    17606   \n"," 2022-05       25619   9833   10977   8122       48155          7026    17703   \n"," 2022-06       25836   9884   11069   8161       48616          7090    17783   \n"," 2022-07       26174  10019   11163   8250       49096          7169    17951   \n"," \n","          Lamphun   AHB_1  Country_Level  \n"," 2016-10     3214   53656       607299.0  \n"," 2016-11     3214   53653       611508.0  \n"," 2016-12     3214   53650       614080.0  \n"," 2017-01     3213   53978       620732.0  \n"," 2017-02     3213   53976       627688.0  \n"," ...          ...     ...            ...  \n"," 2022-03    12499  137869      1213727.0  \n"," 2022-04    12650  139544      1225461.0  \n"," 2022-05    12717  140152      1231355.0  \n"," 2022-06    12807  141246      1239786.0  \n"," 2022-07    12910  142732      1250291.0  \n"," \n"," [70 rows x 10 columns],\n","            Tak  Phitsanulok  Phetchabun  Sukhothai  Uttaradit  AHB_2  \\\n"," 2016-10   2558         7875        8783       7396       5982  32594   \n"," 2016-11   2558         7895        8782       7484       5982  32701   \n"," 2016-12   2558         7895        8781       7521       5982  32737   \n"," 2017-01   2558         7892        8780       7605       6335  33170   \n"," 2017-02   2558         7946        8777       7624       6492  33397   \n"," ...        ...          ...         ...        ...        ...    ...   \n"," 2022-03  10165        18907       15455      12558       9036  66121   \n"," 2022-04  10318        19057       15632      12662       9152  66821   \n"," 2022-05  10320        19148       15671      12703       9171  67013   \n"," 2022-06  10323        19298       15743      12779       9256  67399   \n"," 2022-07  10547        19530       15811      12869       9385  68142   \n"," \n","          Country_Level  \n"," 2016-10       607299.0  \n"," 2016-11       611508.0  \n"," 2016-12       614080.0  \n"," 2017-01       620732.0  \n"," 2017-02       627688.0  \n"," ...                ...  \n"," 2022-03      1213727.0  \n"," 2022-04      1225461.0  \n"," 2022-05      1231355.0  \n"," 2022-06      1239786.0  \n"," 2022-07      1250291.0  \n"," \n"," [70 rows x 7 columns],\n","          Chai_Nat  Kamphaeng_Phet  Phichit  Nakhon_Sawan  Uthai_Thani  AHB_3  \\\n"," 2016-10      3432            6997     5336         10476         3354  29595   \n"," 2016-11      3439            6997     5336         10568         3354  29694   \n"," 2016-12      3442            6996     5336         10568         3354  29696   \n"," 2017-01      3442            6993     5336         10671         3354  29796   \n"," 2017-02      3442            6993     5335         10685         3354  29809   \n"," ...           ...             ...      ...           ...          ...    ...   \n"," 2022-03      7826           16104     9734         25026         8740  67430   \n"," 2022-04      7886           16315     9822         25322         8785  68130   \n"," 2022-05      7911           16374     9845         25359         8801  68290   \n"," 2022-06      7954           16448     9904         25557         8855  68718   \n"," 2022-07      8008           16513     9976         25736         8907  69140   \n"," \n","          Country_Level  \n"," 2016-10       607299.0  \n"," 2016-11       611508.0  \n"," 2016-12       614080.0  \n"," 2017-01       620732.0  \n"," 2017-02       627688.0  \n"," ...                ...  \n"," 2022-03      1213727.0  \n"," 2022-04      1225461.0  \n"," 2022-05      1231355.0  \n"," 2022-06      1239786.0  \n"," 2022-07      1250291.0  \n"," \n"," [70 rows x 7 columns],\n","          Nonthaburi  Pathum_Thani  Phra_Nakhon Si_Ayutthaya  Saraburi  \\\n"," 2016-10        9731          8862                     10474      6518   \n"," 2016-11        9745          8870                     10474      6518   \n"," 2016-12        9751          9748                     10346      6517   \n"," 2017-01        9765          9847                     10916      6515   \n"," 2017-02        9758         10183                     10913      6513   \n"," ...             ...           ...                       ...       ...   \n"," 2022-03       34826         17831                     16303     11156   \n"," 2022-04       35225         18031                     16414     11327   \n"," 2022-05       35361         18051                     16454     11373   \n"," 2022-06       35606         18176                     16573     11464   \n"," 2022-07       35923         18319                     16695     11551   \n"," \n","          Lopburi  Sing_Buri  Ang_Thong  Nakhon_Nayok   AHB_4  Country_Level  \n"," 2016-10     7734       3388       5583          3312   55602       607299.0  \n"," 2016-11     7734       3388       5583          3312   55624       611508.0  \n"," 2016-12     7732       3388       5583          3311   56376       614080.0  \n"," 2017-01     7714       3388       5686          3310   57141       620732.0  \n"," 2017-02     7739       3388       5697          3310   57501       627688.0  \n"," ...          ...        ...        ...           ...     ...            ...  \n"," 2022-03    13945       8854       8916          4820  116651      1213727.0  \n"," 2022-04    14061       8975       8973          4868  117874      1225461.0  \n"," 2022-05    14140       9016       8992          4884  118271      1231355.0  \n"," 2022-06    14230       9094       9040          4923  119106      1239786.0  \n"," 2022-07    14332       9204       9119          4963  120106      1250291.0  \n"," \n"," [70 rows x 10 columns],\n","          Kanchanaburi  Nakhon_Pathom  Ratchaburi  Suphan_Buri  \\\n"," 2016-10          8067           7603        6324         5171   \n"," 2016-11          8238           7603        6494         5231   \n"," 2016-12          8237           7604        6519         5230   \n"," 2017-01          8276           7858        6640         5305   \n"," 2017-02          8276           7872        6766         5330   \n"," ...               ...            ...         ...          ...   \n"," 2022-03         14407          11406       12419        12907   \n"," 2022-04         14536          11443       12626        13047   \n"," 2022-05         14583          11462       12685        13079   \n"," 2022-06         14699          11508       12815        13179   \n"," 2022-07         14826          11564       13027        13307   \n"," \n","          Prachuap_Khiri_Khan  Phetchaburi  Samut_Songkhram  Samut_Sakhon  \\\n"," 2016-10                 6132         4589             1507          3651   \n"," 2016-11                 6198         4633             1522          3772   \n"," 2016-12                 6197         4668             1522          3770   \n"," 2017-01                 6319         4696             1720          3837   \n"," 2017-02                 6622         4731             1725          3947   \n"," ...                      ...          ...              ...           ...   \n"," 2022-03                10347         8806             2945         10015   \n"," 2022-04                10473         8878             3128         10151   \n"," 2022-05                10489         8899             3128         10209   \n"," 2022-06                10575         8947             2945         10340   \n"," 2022-07                10706         9017             3152         10458   \n"," \n","          AHB_5  Country_Level  \n"," 2016-10  43044       607299.0  \n"," 2016-11  43691       611508.0  \n"," 2016-12  43747       614080.0  \n"," 2017-01  44651       620732.0  \n"," 2017-02  45269       627688.0  \n"," ...        ...            ...  \n"," 2022-03  83252      1213727.0  \n"," 2022-04  84282      1225461.0  \n"," 2022-05  84534      1231355.0  \n"," 2022-06  85008      1239786.0  \n"," 2022-07  86057      1250291.0  \n"," \n"," [70 rows x 10 columns],\n","          Chachoengsao  Prachinburi  Sa_Kaeo  Samut_Prakan  Chanthaburi  \\\n"," 2016-10          6456         4271     6913          6004         2572   \n"," 2016-11          6454         4271     6911          6004         2572   \n"," 2016-12          6455         4271     6910          6002         2572   \n"," 2017-01          6456         4271     6910          6000         3356   \n"," 2017-02          6456         4270     6908          6034         3354   \n"," ...               ...          ...      ...           ...          ...   \n"," 2022-03         17553         6847     9893         13608         7103   \n"," 2022-04         17705         6902     9946         13773         7231   \n"," 2022-05         17723         6917     9965         13846         7270   \n"," 2022-06         17801         6959    10008         13953         7372   \n"," 2022-07         17948         7018    10075         14112         7500   \n"," \n","          Chonburi  Trat  Rayong  AHB_6  Country_Level  \n"," 2016-10      7908  1265    3357  38746       607299.0  \n"," 2016-11      7908  1312    3357  38789       611508.0  \n"," 2016-12      7908  1312    3357  38787       614080.0  \n"," 2017-01      8408  1318    3356  40075       620732.0  \n"," 2017-02      8406  1325    3355  40108       627688.0  \n"," ...           ...   ...     ...    ...            ...  \n"," 2022-03     18653  3504    7466  84627      1213727.0  \n"," 2022-04     18936  3541    7593  85627      1225461.0  \n"," 2022-05     19009  3561    7644  85935      1231355.0  \n"," 2022-06     19222  3591    7738  86644      1239786.0  \n"," 2022-07     19514  3625    7837  87629      1250291.0  \n"," \n"," [70 rows x 10 columns],\n","          Kalasin  Khon_Kaen  Maha_Sarakham  Roi_Et   AHB_7  Country_Level\n"," 2016-10     8477      19045          14203   12712   54437       607299.0\n"," 2016-11     8520      19234          14228   12794   54776       611508.0\n"," 2016-12     8532      19470          14233   12852   55087       614080.0\n"," 2017-01     8689      19816          14231   12925   55661       620732.0\n"," 2017-02     8806      20064          14231   12944   56045       627688.0\n"," ...          ...        ...            ...     ...     ...            ...\n"," 2022-03    16722      36856          22628   23368   99574      1213727.0\n"," 2022-04    16809      37331          22886   23491  100517      1225461.0\n"," 2022-05    16862      37389          22928   23547  100726      1231355.0\n"," 2022-06    16962      37627          23028   23652  101269      1239786.0\n"," 2022-07    17039      37917          23217   23828  102001      1250291.0\n"," \n"," [70 rows x 6 columns],\n","          Bueng_Kan   Loei  Nong_Khai  Nong_Bua_Lamphu  Udon_Thani  \\\n"," 2016-10       6450  10454       3474             6155       16452   \n"," 2016-11       6453  10454       3474             6155       16452   \n"," 2016-12       6453  10454       3474             6155       16451   \n"," 2017-01       6578  10476       3479             6156       16454   \n"," 2017-02       6576  10473       3565             6156       16498   \n"," ...            ...    ...        ...              ...         ...   \n"," 2022-03       7628  14085      10383             8924       26313   \n"," 2022-04       7663  14184      10457             8974       26313   \n"," 2022-05       7681  14204      10491             9004       26921   \n"," 2022-06       7711  14281      10544             9043       27021   \n"," 2022-07       7742  14362      10623             9070       27181   \n"," \n","          Nakhon_Phanom  Sakon_Nakhon   AHB_8  Country_Level  \n"," 2016-10           8279         14756   66020       607299.0  \n"," 2016-11           8281         14805   66074       611508.0  \n"," 2016-12           8575         14830   66392       614080.0  \n"," 2017-01           8581         14940   66664       620732.0  \n"," 2017-02           8581         14960   66809       627688.0  \n"," ...                ...           ...     ...            ...  \n"," 2022-03          11933         22756  102022      1213727.0  \n"," 2022-04          11988         22882  102461      1225461.0  \n"," 2022-05          11998         22920  103219      1231355.0  \n"," 2022-06          12042         23038  103680      1239786.0  \n"," 2022-07          12146         23272  104396      1250291.0  \n"," \n"," [70 rows x 9 columns],\n","          Chaiyaphum  Nakhon_Ratchasima  Buriram  Surin   AHB_9  Country_Level\n"," 2016-10       11333              28200    17408  14584   71525       607299.0\n"," 2016-11       11504              29177    17617  14599   72897       611508.0\n"," 2016-12       11526              29236    17745  14670   73177       614080.0\n"," 2017-01       11553              29379    17970  14837   73739       620732.0\n"," 2017-02       14161              30229    18145  15324   77859       627688.0\n"," ...             ...                ...      ...    ...     ...            ...\n"," 2022-03       23217              61826    33541  25809  144393      1213727.0\n"," 2022-04       23427              62345    33727  26191  145690      1225461.0\n"," 2022-05       23533              62562    33815  26899  146809      1231355.0\n"," 2022-06       23689              63020    33994  27467  148170      1239786.0\n"," 2022-07       23890              63468    34396  27841  149595      1250291.0\n"," \n"," [70 rows x 6 columns],\n","          Mukdahan  Yasothon  Sisaket  Ubon_Ratchathani  Amnat_Charoen  AHB_10  \\\n"," 2016-10      4919      6937    11902             20439           2494   46691   \n"," 2016-11      5881      6937    12045             20438           2504   47805   \n"," 2016-12      5890      6937    12379             20436           2510   48152   \n"," 2017-01      6015      6937    12640             20598           2514   48704   \n"," 2017-02      6015      6937    13100             20657           2538   49247   \n"," ...           ...       ...      ...               ...            ...     ...   \n"," 2022-03      9980     12847    26734             45225           6692  101478   \n"," 2022-04     10036     12906    26872             45617           6745  102176   \n"," 2022-05     10053     12935    26940             45725           6776  102429   \n"," 2022-06     10101     12973    27100             45861           6815  102850   \n"," 2022-07     10182     13046    27298             46184           6878  103588   \n"," \n","          Country_Level  \n"," 2016-10       607299.0  \n"," 2016-11       611508.0  \n"," 2016-12       614080.0  \n"," 2017-01       620732.0  \n"," 2017-02       627688.0  \n"," ...                ...  \n"," 2022-03      1213727.0  \n"," 2022-04      1225461.0  \n"," 2022-05      1231355.0  \n"," 2022-06      1239786.0  \n"," 2022-07      1250291.0  \n"," \n"," [70 rows x 7 columns],\n","          Chumphon  Nakhon_Si_Thammarat  Surat_Thani  Krabi  Phang_Nga  Phuket  \\\n"," 2016-10      3775                13009        13674   2705       2870    2036   \n"," 2016-11      3777                13049        13684   2715       2870    2035   \n"," 2016-12      3778                13184        13681   2716       2870    2035   \n"," 2017-01      3804                13338        13681   2802       2868    2033   \n"," 2017-02      3816                13420        13681   2852       2868    2043   \n"," ...           ...                  ...          ...    ...        ...     ...   \n"," 2022-03      6551                26018        26693   5683       4434    4758   \n"," 2022-04      6595                26198        26985   5744       4464    4887   \n"," 2022-05      6615                26268        27067   5769       4479    4896   \n"," 2022-06      6723                26478        27192   5823       4496    4944   \n"," 2022-07      6779                26784        27389   5924       4537    5024   \n"," \n","          Ranong  AHB_11  Country_Level  \n"," 2016-10    1447   39516       607299.0  \n"," 2016-11    1457   39587       611508.0  \n"," 2016-12    1485   39749       614080.0  \n"," 2017-01    1536   40062       620732.0  \n"," 2017-02    1543   40223       627688.0  \n"," ...         ...     ...            ...  \n"," 2022-03    3835   77972      1213727.0  \n"," 2022-04    3894   78767      1225461.0  \n"," 2022-05    3901   78995      1231355.0  \n"," 2022-06    3940   79596      1239786.0  \n"," 2022-07    3976   80413      1250291.0  \n"," \n"," [70 rows x 9 columns],\n","          Phatthalung  Trang  Narathiwat  Pattani  Yala  Songkhla  Satun  \\\n"," 2016-10         6950   9535        9569     6626  3597     14123   2229   \n"," 2016-11         6959   9626        9608     6684  3598     14231   2260   \n"," 2016-12         6970   9682        9683     6735  3598     14330   2281   \n"," 2017-01         6998   9718        9713     6766  3738     14637   2278   \n"," 2017-02         7006   9934        9726     6804  3738     14682   2324   \n"," ...              ...    ...         ...      ...   ...       ...    ...   \n"," 2022-03        11218  14532       14098    11015  7550     29019   5293   \n"," 2022-04        11315  14652       14205    11083  7633     29390   5361   \n"," 2022-05        11360  14699       14262    11126  7662     29519   5391   \n"," 2022-06        11444  14770       14353    11199  7736     29832   5442   \n"," 2022-07        11562  14892       14479    11267  7786     30126   5510   \n"," \n","          AHB_12  Country_Level  \n"," 2016-10   52629       607299.0  \n"," 2016-11   52966       611508.0  \n"," 2016-12   53279       614080.0  \n"," 2017-01   53848       620732.0  \n"," 2017-02   54214       627688.0  \n"," ...         ...            ...  \n"," 2022-03   92725      1213727.0  \n"," 2022-04   93639      1225461.0  \n"," 2022-05   94019      1231355.0  \n"," 2022-06   94776      1239786.0  \n"," 2022-07   95622      1250291.0  \n"," \n"," [70 rows x 9 columns],\n","          Bangkok  AHB_13  Country_Level\n"," 2016-10    23244   23244       607299.0\n"," 2016-11    23251   23251       611508.0\n"," 2016-12    23251   23251       614080.0\n"," 2017-01    23243   23243       620732.0\n"," 2017-02    23231   23231       627688.0\n"," ...          ...     ...            ...\n"," 2022-03    39613   39613      1213727.0\n"," 2022-04    39933   39933      1225461.0\n"," 2022-05    40963   40963      1231355.0\n"," 2022-06    41324   41324      1239786.0\n"," 2022-07    40870   40870      1250291.0\n"," \n"," [70 rows x 3 columns],\n","          Chiang_Rai    Nan  Phayao  Phrae  Chiang_Mai  Mae_Hong_Son  Lampang  \\\n"," 2016-10       10383   5315    4266   4057       15408          2002     9011   \n"," 2016-11       10383   5315    4265   4057       15406          2002     9011   \n"," 2016-12       10382   5315    4265   4057       15404          2002     9011   \n"," 2017-01       10382   5655    4265   4057       15393          2002     9011   \n"," 2017-02       10382   5655    4264   4057       15392          2002     9011   \n"," ...             ...    ...     ...    ...         ...           ...      ...   \n"," 2022-03       25223   9711   10788   7988       47292          6924    17444   \n"," 2022-04       25456   9781   10932   8095       48020          7004    17606   \n"," 2022-05       25619   9833   10977   8122       48155          7026    17703   \n"," 2022-06       25836   9884   11069   8161       48616          7090    17783   \n"," 2022-07       26174  10019   11163   8250       49096          7169    17951   \n"," \n","          Lamphun    Tak  Phitsanulok  ...  AHB_5  AHB_6   AHB_7   AHB_8  \\\n"," 2016-10     3214   2558         7875  ...  43044  38746   54437   66020   \n"," 2016-11     3214   2558         7895  ...  43691  38789   54776   66074   \n"," 2016-12     3214   2558         7895  ...  43747  38787   55087   66392   \n"," 2017-01     3213   2558         7892  ...  44651  40075   55661   66664   \n"," 2017-02     3213   2558         7946  ...  45269  40108   56045   66809   \n"," ...          ...    ...          ...  ...    ...    ...     ...     ...   \n"," 2022-03    12499  10165        18907  ...  83252  84627   99574  102022   \n"," 2022-04    12650  10318        19057  ...  84282  85627  100517  102461   \n"," 2022-05    12717  10320        19148  ...  84534  85935  100726  103219   \n"," 2022-06    12807  10323        19298  ...  85008  86644  101269  103680   \n"," 2022-07    12910  10547        19530  ...  86057  87629  102001  104396   \n"," \n","           AHB_9  AHB_10  AHB_11  AHB_12  AHB_13  Country_Level  \n"," 2016-10   71525   46691   39516   52629   23244       607299.0  \n"," 2016-11   72897   47805   39587   52966   23251       611508.0  \n"," 2016-12   73177   48152   39749   53279   23251       614080.0  \n"," 2017-01   73739   48704   40062   53848   23243       620732.0  \n"," 2017-02   77859   49247   40223   54214   23231       627688.0  \n"," ...         ...     ...     ...     ...     ...            ...  \n"," 2022-03  144393  101478   77972   92725   39613      1213727.0  \n"," 2022-04  145690  102176   78767   93639   39933      1225461.0  \n"," 2022-05  146809  102429   78995   94019   40963      1231355.0  \n"," 2022-06  148170  102850   79596   94776   41324      1239786.0  \n"," 2022-07  149595  103588   80413   95622   40870      1250291.0  \n"," \n"," [70 rows x 91 columns]]"]},"metadata":{},"execution_count":4}],"source":["df_list"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SU_ny31AUe6O","executionInfo":{"status":"ok","timestamp":1665682947613,"user_tz":-420,"elapsed":14,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"}}},"outputs":[],"source":["# split a univariate sequence into samples\n","def uni_split_sequence(sequence, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the sequence\n","        if end_ix > len(sequence)-1:\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","\n","    # split a multivariate sequence into samples\n","def multi_split_sequences(sequences, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequences)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the dataset\n","        if end_ix > len(sequences):\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","\n","def get_scaler(scaler):\n","    scalers = {\n","        \"minmax\": MinMaxScaler,\n","        \"standard\": StandardScaler,\n","        \"maxabs\": MaxAbsScaler,\n","        \"robust\": RobustScaler,\n","    }\n","    return scalers.get(scaler.lower())()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3pQoCYDv5gjk","executionInfo":{"status":"error","timestamp":1665683021610,"user_tz":-420,"elapsed":74011,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"}},"outputId":"d25a3590-5ae4-4d5d-ab96-2f41b8aa6dbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["PROGRESS: [ 1 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 12,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.16424726516056007,\n","  \"MSE_normalize\": 0.02713105468137349,\n","  \"RMSE_normalize\": 0.1647150712028911,\n","  \"MAPE_normalize\": 0.17260819884776493,\n","  \"MAE\": 7061.481026785715,\n","  \"MSE\": 50148964.468340196,\n","  \"RMSE\": 7081.593356606986,\n","  \"MAPE\": 0.07547127234695963\n","}\n","Percent CPU Usage: 42.0\n","Percent Ram Usage: 9.2\n","2022-10-14 00:42:35.991551+07:00\n","PROGRESS: [ 2 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 17,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.04865813182980621,\n","  \"MSE_normalize\": 0.0024034995742340357,\n","  \"RMSE_normalize\": 0.049025499224730346,\n","  \"MAPE_normalize\": 0.051055193560424525,\n","  \"MAE\": 2091.9587053571427,\n","  \"MSE\": 4442623.639831541,\n","  \"RMSE\": 2107.7532208091966,\n","  \"MAPE\": 0.02234307299786324\n","}\n","Percent CPU Usage: 91.0\n","Percent Ram Usage: 10.4\n","2022-10-14 00:42:44.248179+07:00\n","PROGRESS: [ 3 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 27,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.07628126582976698,\n","  \"MSE_normalize\": 0.005860128173386395,\n","  \"RMSE_normalize\": 0.0765514740118464,\n","  \"MAPE_normalize\": 0.08014789285489418,\n","  \"MAE\": 3279.5602678571427,\n","  \"MSE\": 10831848.105800081,\n","  \"RMSE\": 3291.1773130295,\n","  \"MAPE\": 0.035047956439791264\n","}\n","Percent CPU Usage: 79.7\n","Percent Ram Usage: 11.4\n","2022-10-14 00:42:52.657039+07:00\n","PROGRESS: [ 4 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 17,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.10205505503123094,\n","  \"MSE_normalize\": 0.010676818305846296,\n","  \"RMSE_normalize\": 0.10332869062291604,\n","  \"MAPE_normalize\": 0.10694960153188866,\n","  \"MAE\": 4387.651785714285,\n","  \"MSE\": 19735003.252580915,\n","  \"RMSE\": 4442.409622331209,\n","  \"MAPE\": 0.04683678951693569\n","}\n","Percent CPU Usage: 71.9\n","Percent Ram Usage: 11.7\n","2022-10-14 00:42:57.851461+07:00\n","PROGRESS: [ 5 / 7560 ]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f777f7b10e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 14,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.1931424644594187,\n","  \"MSE_normalize\": 0.03755778746218359,\n","  \"RMSE_normalize\": 0.19379831645858947,\n","  \"MAPE_normalize\": 0.20292447585757917,\n","  \"MAE\": 8303.77232142857,\n","  \"MSE\": 69421712.46557617,\n","  \"RMSE\": 8331.969302966507,\n","  \"MAPE\": 0.08873904939457522\n","}\n","Percent CPU Usage: 53.7\n","Percent Ram Usage: 11.7\n","2022-10-14 00:43:02.200491+07:00\n","PROGRESS: [ 6 / 7560 ]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f777f702440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 10,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.1698480411517274,\n","  \"MSE_normalize\": 0.029387145499277848,\n","  \"RMSE_normalize\": 0.1714267934112922,\n","  \"MAPE_normalize\": 0.17812442105777176,\n","  \"MAE\": 7302.274553571428,\n","  \"MSE\": 54319111.12248884,\n","  \"RMSE\": 7370.150006783366,\n","  \"MAPE\": 0.07797437220856088\n","}\n","Percent CPU Usage: 63.1\n","Percent Ram Usage: 11.8\n","2022-10-14 00:43:05.827713+07:00\n","PROGRESS: [ 7 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 11,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.24024770017228755,\n","  \"MSE_normalize\": 0.05811088170142669,\n","  \"RMSE_normalize\": 0.24106198725934933,\n","  \"MAPE_normalize\": 0.2524141496019566,\n","  \"MAE\": 10328.96986607143,\n","  \"MSE\": 107412051.2562343,\n","  \"RMSE\": 10363.978543794574,\n","  \"MAPE\": 0.11038127282850278\n","}\n","Percent CPU Usage: 51.5\n","Percent Ram Usage: 12.1\n","2022-10-14 00:43:09.021713+07:00\n","PROGRESS: [ 8 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 15,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.1311718984591615,\n","  \"MSE_normalize\": 0.017412676237513497,\n","  \"RMSE_normalize\": 0.13195709998902483,\n","  \"MAPE_normalize\": 0.1376907605640457,\n","  \"MAE\": 5639.473214285715,\n","  \"MSE\": 32185552.430873327,\n","  \"RMSE\": 5673.231216059621,\n","  \"MAPE\": 0.06024294280234732\n","}\n","Percent CPU Usage: 54.2\n","Percent Ram Usage: 11.9\n","2022-10-14 00:43:13.186362+07:00\n","PROGRESS: [ 9 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 19,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.25253882506111636,\n","  \"MSE_normalize\": 0.06417089362108613,\n","  \"RMSE_normalize\": 0.25331974581758554,\n","  \"MAPE_normalize\": 0.2653607218732443,\n","  \"MAE\": 10857.39955357143,\n","  \"MSE\": 118613306.64001465,\n","  \"RMSE\": 10890.973631407554,\n","  \"MAPE\": 0.11603467112810792\n","}\n","Percent CPU Usage: 52.0\n","Percent Ram Usage: 11.9\n","2022-10-14 00:43:16.581203+07:00\n","PROGRESS: [ 10 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 30,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.15921195843437688,\n","  \"MSE_normalize\": 0.02603245865823871,\n","  \"RMSE_normalize\": 0.16134577359893476,\n","  \"MAPE_normalize\": 0.1668149958998107,\n","  \"MAE\": 6845.0,\n","  \"MSE\": 48118342.514665864,\n","  \"RMSE\": 6936.738607924178,\n","  \"MAPE\": 0.07306192211069924\n","}\n","Percent CPU Usage: 54.7\n","Percent Ram Usage: 11.9\n","2022-10-14 00:43:19.717074+07:00\n","PROGRESS: [ 11 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 10,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 1.3538961658737994,\n","  \"MSE_normalize\": 1.8350842162992418,\n","  \"RMSE_normalize\": 1.354652802861029,\n","  \"MAPE_normalize\": 1.4247882816816797,\n","  \"MAE\": 58208.05803571428,\n","  \"MSE\": 3391966107.683341,\n","  \"RMSE\": 58240.588146784205,\n","  \"MAPE\": 0.6224890838182144\n","}\n","Percent CPU Usage: 53.9\n","Percent Ram Usage: 11.9\n","2022-10-14 00:43:22.625583+07:00\n","PROGRESS: [ 12 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 14,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.3087024766637252,\n","  \"MSE_normalize\": 0.09594271454244306,\n","  \"RMSE_normalize\": 0.3097462098919744,\n","  \"MAPE_normalize\": 0.3243361349578479,\n","  \"MAE\": 13272.04575892857,\n","  \"MSE\": 177340330.80038887,\n","  \"RMSE\": 13316.918968004156,\n","  \"MAPE\": 0.14183275229198752\n","}\n","Percent CPU Usage: 60.6\n","Percent Ram Usage: 11.4\n","2022-10-14 00:43:26.953261+07:00\n","PROGRESS: [ 13 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 7,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.6109352913503641,\n","  \"MSE_normalize\": 0.373731936076231,\n","  \"RMSE_normalize\": 0.6113361890778518,\n","  \"MAPE_normalize\": 0.6428654352653584,\n","  \"MAE\": 26265.940848214286,\n","  \"MSE\": 690805371.9213954,\n","  \"RMSE\": 26283.176594951292,\n","  \"MAPE\": 0.28088209694081845\n","}\n","Percent CPU Usage: 51.4\n","Percent Ram Usage: 11.4\n","2022-10-14 00:43:30.363185+07:00\n","PROGRESS: [ 14 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 43,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.6143882182245248,\n","  \"MSE_normalize\": 0.37877726344313495,\n","  \"RMSE_normalize\": 0.6154488308894046,\n","  \"MAPE_normalize\": 0.646009765787565,\n","  \"MAE\": 26414.39285714286,\n","  \"MSE\": 700131165.3878697,\n","  \"RMSE\": 26459.991787373438,\n","  \"MAPE\": 0.28237643817066205\n","}\n","Percent CPU Usage: 64.9\n","Percent Ram Usage: 11.5\n","2022-10-14 00:43:34.142471+07:00\n","PROGRESS: [ 15 / 7560 ]\n","{\n","  \"model\": \"GRU\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"GRU_hidden_units\": 8,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 7,\n","  \"patience_list\": 3,\n","  \"MAE_normalize\": 0.19679556501810838,\n","  \"MSE_normalize\": 0.038878180329427955,\n","  \"RMSE_normalize\": 0.19717550641351972,\n","  \"MAPE_normalize\": 0.20690390527667882,\n","  \"MAE\": 8460.831473214286,\n","  \"MSE\": 71862349.67769077,\n","  \"RMSE\": 8477.16637076864,\n","  \"MAPE\": 0.09044445478941389\n","}\n","Percent CPU Usage: 57.0\n","Percent Ram Usage: 11.4\n","2022-10-14 00:43:40.444343+07:00\n","PROGRESS: [ 16 / 7560 ]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-7b338d532038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                 \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                                 \u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    785\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 786\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mautograph_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 ))\n\u001b[1;32m   1125\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[1;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \"\"\"\n\u001b[1;32m    537\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 538\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     self._assert_valid_dtypes([\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[0;34m(self, op, *doutputs)\u001b[0m\n\u001b[1;32m    664\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m     \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m           func_graph=backwards_graph)\n\u001b[0m\u001b[1;32m    648\u001b[0m       \u001b[0mbackwards_graph_captures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m       captures_from_forward = [\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             src_graph=self._func_graph)\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_grad_fn_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m       stateful_parallelism)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbody_grad_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_op_needs_rewrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[1;32m    691\u001b[0m                                          \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhile_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                                          body_graph_inputs, body_graph_outputs),\n\u001b[0;32m--> 693\u001b[0;31m       acd_record_initial_resource_uses=stateful_parallelism)\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0;31m# Update the list of outputs with tensors corresponding to the captured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    686\u001b[0m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    744\u001b[0m   grad_outs = gradients_util._GradientsHelper(\n\u001b[1;32m    745\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m       unconnected_gradients=\"zero\")\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m   \u001b[0;31m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_AddGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n\u001b[0;32m-> 1302\u001b[0;31m       SmartBroadcastGradientArgs(x, y, grad))\n\u001b[0m\u001b[1;32m   1303\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mskip_input_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36mSmartBroadcastGradientArgs\u001b[0;34m(x, y, grad)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mbroadcast_gradient_args\u001b[0;34m(s0, s1, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m--> 772\u001b[0;31m         \"BroadcastGradientArgs\", s0=s0, s1=s1, name=name)\n\u001b[0m\u001b[1;32m    773\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    797\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    798\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0mop_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         compute_device=compute_device)\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m   def _move_op_to_forward_graph(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mctxt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AddValue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    757\u001b[0m               f\"it was defined in {tensor.graph}, which is out of scope.\")\n\u001b[1;32m    758\u001b[0m         \u001b[0minner_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m   1214\u001b[0m       \u001b[0;31m# match.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cond_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cond_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[0;31m# Capture the accumulator tensor list in the gradient graph directly from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    757\u001b[0m               f\"it was defined in {tensor.graph}, which is out of scope.\")\n\u001b[1;32m    758\u001b[0m         \u001b[0minner_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 766\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;31m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     placeholder = graph_placeholder(\n\u001b[1;32m   1315\u001b[0m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0;32m-> 1316\u001b[0;31m   \u001b[0mhandle_data_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/handle_data_util.py\u001b[0m in \u001b[0;36mcopy_handle_data\u001b[0;34m(source_t, target_t)\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mhandle_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resource_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     if (handle_data is not None\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mand\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         and handle_data.shape_and_type):\n\u001b[1;32m     49\u001b[0m       \u001b[0mset_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%matplotlib inline\n","# define scope of configs\n","AHB_list = [11, 12, 13]\n","GRU_hidden_units = [8, 16, 32, 64, 128]\n","n_layer = [1, 2, 3]\n","n_batch = [2, 4, 8, 16, 32, 64, 128]\n","n_steps = [5]\n","patience_list = [3, 5, 7, 10]\n","mul_uni = ['uni','mul']\n","dropouts = [0.2, 0.3, 0.5]\n","\n","\n","timezone_offset = 7.0  # Bangkok Time (UTC+07:00)\n","tzinfo = timezone(timedelta(hours=timezone_offset))\n","count = 1\n","performance_json = []\n","for g in AHB_list:\n","    for h in patience_list:\n","        for a in n_steps:\n","            for b in dropouts:\n","                for c in GRU_hidden_units:\n","                    for d in n_layer:\n","                        for e in n_batch:\n","                            for f in mul_uni:\n","\n","                                print('PROGRESS: [ ' + str(count) + ' / ' + str(len(dropouts)*len(AHB_list)*len(n_steps)*len(GRU_hidden_units)*len(n_layer)*len(n_batch)*len(patience_list)*len(mul_uni)) + ' ]')\n","                                \n","                                if f == 'uni':\n","                                    if g == 13:\n","                                        raw_seq = list(df_list[g]['Country_Level'])\n","                                        ahb = 'Country_Level'\n","                                    else:    \n","                                        raw_seq = list(df_list[g]['AHB_'+str(g+1)])\n","                                        ahb = 'AHB_'+str(g+1)\n","                                    n_features = 1\n","                                    scaler = get_scaler('minmax')\n","                                    raw_seq_arr = scaler.fit_transform(np.array(raw_seq).reshape(len(raw_seq),-1))\n","                                    X, y = uni_split_sequence(raw_seq_arr, a)\n","                                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.9, shuffle=False, stratify=None)\n","                                    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n","                                    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n","                                if f == 'mul':\n","                                    if g == 13:\n","                                        raw_seq = list(df_list[13].drop(df_list[13].columns[:77], axis=1).values)\n","                                        ahb = 'Country_Level'\n","                                        scaler_y = get_scaler('minmax')\n","                                        scaler_y.fit(np.array(df_list[13]['Country_Level']).reshape(len(df_list[13]['Country_Level']),-1))\n","                                    else:    \n","                                        raw_seq = list(df_list[g].drop(['Country_Level'], axis=1).values)\n","                                        ahb = 'AHB_'+str(g+1)\n","                                        scaler_y = get_scaler('minmax')\n","                                        scaler_y.fit(np.array(df_list[g]['AHB_'+str(g+1)]).reshape(len(df_list[13]['AHB_'+str(g+1)]),-1))\n","                                    n_features = len(raw_seq[0])-1\n","                                    scaler = get_scaler('minmax')\n","                                    raw_seq_arr = scaler.fit_transform(np.array(raw_seq))\n","                                    X, y = multi_split_sequences(raw_seq_arr, a)\n","                                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.9, shuffle=False, stratify=None)\n","                                    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n","                                    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n","\n","                                callback = EarlyStopping(monitor='loss', patience=h)\n","                                model = Sequential()\n","                                if d == 1:\n","                                    model.add(GRU(units=c, return_sequences=False, input_shape=(a,n_features), activation='tanh'))\n","                                    model.add(Dropout(b))\n","                                if d == 2:\n","                                    model.add(GRU(units=c, return_sequences=True, input_shape=(a,n_features), activation='tanh'))\n","                                    model.add(Dropout(b))\n","                                    model.add(GRU(units=c, return_sequences=False, activation='tanh'))\n","                                    model.add(Dropout(b))\n","                                if d == 3:\n","                                    model.add(GRU(units=c, return_sequences=True, input_shape=(a,n_features), activation='tanh'))\n","                                    model.add(Dropout(b))\n","                                    model.add(GRU(units=c, return_sequences=True, input_shape=(a,n_features), activation='tanh'))\n","                                    model.add(Dropout(b))\n","                                    model.add(GRU(units=c, return_sequences=False, activation='tanh'))\n","                                    model.add(Dropout(b))\n","                                model.add(Dense(units=1, kernel_initializer='he_uniform', activation='linear'))\n","                                model.compile(loss='mse', optimizer='adam')  \n","                                history = model.fit(X_train, y_train, epochs=2000, batch_size=e, verbose=0, callbacks=[callback])\n","                                last_epoch = len(history.history['loss']) \n","\n","                                yhat = model.predict(X_test, verbose=0)\n","                                yhat = yhat.reshape(yhat.shape[0],-1)\n","                                mae = mean_absolute_error(y_test, yhat)\n","                                mse = mean_squared_error(y_test, yhat)\n","                                rmse = mean_squared_error(y_test, yhat, squared = False)\n","                                mape = mean_absolute_percentage_error(y_test, yhat)\n","                                \n","                                if f == 'uni':\n","                                    yhat_inverse = scaler.inverse_transform(yhat)\n","                                    y_test_inverse = scaler.inverse_transform(y_test)\n","                                if f == 'mul':\n","                                    yhat_inverse = scaler_y.inverse_transform(yhat)\n","                                    y_test_inverse = scaler_y.inverse_transform(y_test.reshape(len(y_test),-1))\n","\n","\n","                                mae_inverse = mean_absolute_error(y_test_inverse, yhat_inverse)\n","                                mse_inverse = mean_squared_error(y_test_inverse, yhat_inverse)\n","                                rmse_inverse = mean_squared_error(y_test_inverse, yhat_inverse, squared = False)\n","                                mape_inverse = mean_absolute_percentage_error(y_test_inverse, yhat_inverse)\n","\n","                                performance_json.append({'model': 'GRU', 'AHB_number': ahb, 'Multi_Uni': f, \\\n","                                                         'n_layer': d, 'GRU_hidden_units': c, 'dropouts': b,'n_batch': e,\\\n","                                                         'n_steps': a, 'last_epoch': last_epoch, 'patience_list': h, 'MAE_normalize': float(mae), \\\n","                                                         'MSE_normalize': float(mse), 'RMSE_normalize': float(rmse), 'MAPE_normalize': float(mape), \\\n","                                                         'MAE': float(mae_inverse), 'MSE': float(mse_inverse), 'RMSE': float(rmse_inverse), 'MAPE': float(mape_inverse)})\n","                                \n","\n","                                json_formatted_str = json.dumps(performance_json[-1], indent=2)\n","                                print(json_formatted_str)\n","                                print('Percent CPU Usage: ' + str(psutil.cpu_percent()))\n","                                print('Percent Ram Usage: ' + str(psutil.virtual_memory()[2]))\n","                                print(datetime.now(tzinfo))\n","\n","                                count = count + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RsB2cwuT2feQ"},"outputs":[],"source":["name = \"all_performance_GRU_5nsteps_AHB12-13-C\"\n","json.dump(performance_json, open(name + \".json\",\"w\"))\n","df_json = pd.read_json('/content/' + name + '.json')\n","df_json.to_csv('/content/' + name + '.csv', index=False)\n","#! cp /content/all_performance_GRU_5nsteps_AHB12-13-C.json /content/drive/MyDrive/Depression\n","! cp /content/all_performance_GRU_5nsteps_AHB12-13-C.csv /content/drive/MyDrive/Depression"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"veQ12ze82xhZ","outputId":"7e8a07b5-86cc-4558-c419-c1b19a537238"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-27f73999-2639-403f-9490-3466bf7cfb79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>AHB_number</th>\n","      <th>Multi_Uni</th>\n","      <th>n_layer</th>\n","      <th>GRU_hidden_units</th>\n","      <th>dropouts</th>\n","      <th>n_batch</th>\n","      <th>n_steps</th>\n","      <th>last_epoch</th>\n","      <th>patience_list</th>\n","      <th>MAE_normalize</th>\n","      <th>MSE_normalize</th>\n","      <th>RMSE_normalize</th>\n","      <th>MAPE_normalize</th>\n","      <th>MAE</th>\n","      <th>MSE</th>\n","      <th>RMSE</th>\n","      <th>MAPE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GRU</td>\n","      <td>AHB_12</td>\n","      <td>uni</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>16</td>\n","      <td>3</td>\n","      <td>0.035619</td>\n","      <td>0.001312</td>\n","      <td>0.036222</td>\n","      <td>0.037308</td>\n","      <td>1531.378348</td>\n","      <td>2.425171e+06</td>\n","      <td>1557.296032</td>\n","      <td>0.016343</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GRU</td>\n","      <td>AHB_12</td>\n","      <td>mul</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>25</td>\n","      <td>3</td>\n","      <td>0.072718</td>\n","      <td>0.005489</td>\n","      <td>0.074088</td>\n","      <td>0.076114</td>\n","      <td>3126.373884</td>\n","      <td>1.014604e+07</td>\n","      <td>3185.284680</td>\n","      <td>0.033356</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GRU</td>\n","      <td>AHB_12</td>\n","      <td>uni</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>3</td>\n","      <td>0.101252</td>\n","      <td>0.010391</td>\n","      <td>0.101937</td>\n","      <td>0.106263</td>\n","      <td>4353.140625</td>\n","      <td>1.920700e+07</td>\n","      <td>4382.578975</td>\n","      <td>0.046498</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GRU</td>\n","      <td>AHB_12</td>\n","      <td>mul</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>27</td>\n","      <td>3</td>\n","      <td>0.063064</td>\n","      <td>0.004031</td>\n","      <td>0.063488</td>\n","      <td>0.066189</td>\n","      <td>2711.309152</td>\n","      <td>7.450408e+06</td>\n","      <td>2729.543488</td>\n","      <td>0.028962</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GRU</td>\n","      <td>AHB_12</td>\n","      <td>uni</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0.2</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>21</td>\n","      <td>3</td>\n","      <td>0.232467</td>\n","      <td>0.054429</td>\n","      <td>0.233300</td>\n","      <td>0.244220</td>\n","      <td>9994.454241</td>\n","      <td>1.006060e+08</td>\n","      <td>10030.252823</td>\n","      <td>0.106803</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7555</th>\n","      <td>GRU</td>\n","      <td>Country_Level</td>\n","      <td>mul</td>\n","      <td>3</td>\n","      <td>128</td>\n","      <td>0.5</td>\n","      <td>32</td>\n","      <td>5</td>\n","      <td>39</td>\n","      <td>10</td>\n","      <td>0.020257</td>\n","      <td>0.000436</td>\n","      <td>0.020879</td>\n","      <td>0.021013</td>\n","      <td>13025.250000</td>\n","      <td>1.802366e+08</td>\n","      <td>13425.221591</td>\n","      <td>0.010612</td>\n","    </tr>\n","    <tr>\n","      <th>7556</th>\n","      <td>GRU</td>\n","      <td>Country_Level</td>\n","      <td>uni</td>\n","      <td>3</td>\n","      <td>128</td>\n","      <td>0.5</td>\n","      <td>64</td>\n","      <td>5</td>\n","      <td>62</td>\n","      <td>10</td>\n","      <td>0.042779</td>\n","      <td>0.001850</td>\n","      <td>0.043015</td>\n","      <td>0.044550</td>\n","      <td>27506.500000</td>\n","      <td>7.649677e+08</td>\n","      <td>27658.049279</td>\n","      <td>0.022455</td>\n","    </tr>\n","    <tr>\n","      <th>7557</th>\n","      <td>GRU</td>\n","      <td>Country_Level</td>\n","      <td>mul</td>\n","      <td>3</td>\n","      <td>128</td>\n","      <td>0.5</td>\n","      <td>64</td>\n","      <td>5</td>\n","      <td>41</td>\n","      <td>10</td>\n","      <td>0.082230</td>\n","      <td>0.006807</td>\n","      <td>0.082504</td>\n","      <td>0.085681</td>\n","      <td>52872.910714</td>\n","      <td>2.814253e+09</td>\n","      <td>53049.531190</td>\n","      <td>0.043175</td>\n","    </tr>\n","    <tr>\n","      <th>7558</th>\n","      <td>GRU</td>\n","      <td>Country_Level</td>\n","      <td>uni</td>\n","      <td>3</td>\n","      <td>128</td>\n","      <td>0.5</td>\n","      <td>128</td>\n","      <td>5</td>\n","      <td>31</td>\n","      <td>10</td>\n","      <td>0.125343</td>\n","      <td>0.015744</td>\n","      <td>0.125475</td>\n","      <td>0.130735</td>\n","      <td>80594.196429</td>\n","      <td>6.509186e+09</td>\n","      <td>80679.526441</td>\n","      <td>0.065844</td>\n","    </tr>\n","    <tr>\n","      <th>7559</th>\n","      <td>GRU</td>\n","      <td>Country_Level</td>\n","      <td>mul</td>\n","      <td>3</td>\n","      <td>128</td>\n","      <td>0.5</td>\n","      <td>128</td>\n","      <td>5</td>\n","      <td>40</td>\n","      <td>10</td>\n","      <td>0.074321</td>\n","      <td>0.005572</td>\n","      <td>0.074644</td>\n","      <td>0.077416</td>\n","      <td>47788.053571</td>\n","      <td>2.303564e+09</td>\n","      <td>47995.453637</td>\n","      <td>0.039016</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7560 rows × 18 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27f73999-2639-403f-9490-3466bf7cfb79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-27f73999-2639-403f-9490-3466bf7cfb79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-27f73999-2639-403f-9490-3466bf7cfb79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     model     AHB_number Multi_Uni  n_layer  GRU_hidden_units  dropouts  \\\n","0      GRU         AHB_12       uni        1                 8       0.2   \n","1      GRU         AHB_12       mul        1                 8       0.2   \n","2      GRU         AHB_12       uni        1                 8       0.2   \n","3      GRU         AHB_12       mul        1                 8       0.2   \n","4      GRU         AHB_12       uni        1                 8       0.2   \n","...    ...            ...       ...      ...               ...       ...   \n","7555   GRU  Country_Level       mul        3               128       0.5   \n","7556   GRU  Country_Level       uni        3               128       0.5   \n","7557   GRU  Country_Level       mul        3               128       0.5   \n","7558   GRU  Country_Level       uni        3               128       0.5   \n","7559   GRU  Country_Level       mul        3               128       0.5   \n","\n","      n_batch  n_steps  last_epoch  patience_list  MAE_normalize  \\\n","0           2        5          16              3       0.035619   \n","1           2        5          25              3       0.072718   \n","2           4        5          15              3       0.101252   \n","3           4        5          27              3       0.063064   \n","4           8        5          21              3       0.232467   \n","...       ...      ...         ...            ...            ...   \n","7555       32        5          39             10       0.020257   \n","7556       64        5          62             10       0.042779   \n","7557       64        5          41             10       0.082230   \n","7558      128        5          31             10       0.125343   \n","7559      128        5          40             10       0.074321   \n","\n","      MSE_normalize  RMSE_normalize  MAPE_normalize           MAE  \\\n","0          0.001312        0.036222        0.037308   1531.378348   \n","1          0.005489        0.074088        0.076114   3126.373884   \n","2          0.010391        0.101937        0.106263   4353.140625   \n","3          0.004031        0.063488        0.066189   2711.309152   \n","4          0.054429        0.233300        0.244220   9994.454241   \n","...             ...             ...             ...           ...   \n","7555       0.000436        0.020879        0.021013  13025.250000   \n","7556       0.001850        0.043015        0.044550  27506.500000   \n","7557       0.006807        0.082504        0.085681  52872.910714   \n","7558       0.015744        0.125475        0.130735  80594.196429   \n","7559       0.005572        0.074644        0.077416  47788.053571   \n","\n","               MSE          RMSE      MAPE  \n","0     2.425171e+06   1557.296032  0.016343  \n","1     1.014604e+07   3185.284680  0.033356  \n","2     1.920700e+07   4382.578975  0.046498  \n","3     7.450408e+06   2729.543488  0.028962  \n","4     1.006060e+08  10030.252823  0.106803  \n","...            ...           ...       ...  \n","7555  1.802366e+08  13425.221591  0.010612  \n","7556  7.649677e+08  27658.049279  0.022455  \n","7557  2.814253e+09  53049.531190  0.043175  \n","7558  6.509186e+09  80679.526441  0.065844  \n","7559  2.303564e+09  47995.453637  0.039016  \n","\n","[7560 rows x 18 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_json"]}],"metadata":{"colab":{"background_execution":"on","collapsed_sections":[],"provenance":[],"mount_file_id":"1gSO2C57FbpZckaSUwe74WXXQLSii4HcF","authorship_tag":"ABX9TyOe/isVB6Fe9ox2CFgWqZXr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}