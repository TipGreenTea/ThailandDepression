{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237606,"status":"ok","timestamp":1666413947126,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"},"user_tz":-420},"id":"45kEgxlPJkhU","outputId":"957891b0-1fa1-466e-e046-f85b833437e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tsai\n","  Downloading tsai-0.3.2-py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 9.7 MB/s \n","\u001b[?25hCollecting pyts\u003e=0.12.0\n","  Downloading pyts-0.12.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 54.0 MB/s \n","\u001b[?25hRequirement already satisfied: psutil\u003e=5.4.8 in /usr/local/lib/python3.7/dist-packages (from tsai) (5.4.8)\n","Requirement already satisfied: fastai\u003e=2.7.9 in /usr/local/lib/python3.7/dist-packages (from tsai) (2.7.9)\n","Requirement already satisfied: torch\u003c1.14,\u003e=1.7.0 in /usr/local/lib/python3.7/dist-packages (from tsai) (1.12.1+cu113)\n","Requirement already satisfied: imbalanced-learn\u003e=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tsai) (0.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (21.3)\n","Requirement already satisfied: pillow\u003e6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (7.1.2)\n","Requirement already satisfied: fastcore\u003c1.6,\u003e=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (1.5.27)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (1.3.5)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (21.1.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (1.0.2)\n","Requirement already satisfied: fastdownload\u003c2,\u003e=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (0.0.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (3.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (1.7.3)\n","Requirement already satisfied: fastprogress\u003e=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (1.0.3)\n","Requirement already satisfied: spacy\u003c4 in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (3.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (2.23.0)\n","Requirement already satisfied: torchvision\u003e=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (0.13.1+cu113)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai\u003e=2.7.9-\u003etsai) (6.0)\n","Requirement already satisfied: numpy\u003e=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn\u003e=0.8.0-\u003etsai) (1.21.6)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn\u003e=0.8.0-\u003etsai) (1.2.0)\n","Requirement already satisfied: numba\u003e=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts\u003e=0.12.0-\u003etsai) (0.56.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba\u003e=0.48.0-\u003epyts\u003e=0.12.0-\u003etsai) (4.13.0)\n","Requirement already satisfied: llvmlite\u003c0.40,\u003e=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba\u003e=0.48.0-\u003epyts\u003e=0.12.0-\u003etsai) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba\u003e=0.48.0-\u003epyts\u003e=0.12.0-\u003etsai) (57.4.0)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003efastai\u003e=2.7.9-\u003etsai) (3.1.0)\n","Requirement already satisfied: thinc\u003c8.2.0,\u003e=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (8.1.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,\u003c1.10.0,\u003e=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (1.9.2)\n","Requirement already satisfied: murmurhash\u003c1.1.0,\u003e=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (1.0.9)\n","Requirement already satisfied: cymem\u003c2.1.0,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (2.0.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (2.11.3)\n","Requirement already satisfied: preshed\u003c3.1.0,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (3.0.8)\n","Requirement already satisfied: pathy\u003e=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (0.6.2)\n","Requirement already satisfied: tqdm\u003c5.0.0,\u003e=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (4.64.1)\n","Requirement already satisfied: typer\u003c0.5.0,\u003e=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (0.4.2)\n","Requirement already satisfied: srsly\u003c3.0.0,\u003e=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (2.4.4)\n","Requirement already satisfied: spacy-legacy\u003c3.1.0,\u003e=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (3.0.10)\n","Requirement already satisfied: langcodes\u003c4.0.0,\u003e=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (3.3.0)\n","Requirement already satisfied: wasabi\u003c1.1.0,\u003e=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (0.10.1)\n","Requirement already satisfied: spacy-loggers\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (1.0.3)\n","Requirement already satisfied: catalogue\u003c2.1.0,\u003e=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (2.0.8)\n","Requirement already satisfied: typing-extensions\u003c4.2.0,\u003e=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (4.1.1)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue\u003c2.1.0,\u003e=2.0.6-\u003espacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003efastai\u003e=2.7.9-\u003etsai) (3.0.9)\n","Requirement already satisfied: smart-open\u003c6.0.0,\u003e=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy\u003e=0.3.5-\u003espacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (5.2.1)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efastai\u003e=2.7.9-\u003etsai) (2022.9.24)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efastai\u003e=2.7.9-\u003etsai) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efastai\u003e=2.7.9-\u003etsai) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efastai\u003e=2.7.9-\u003etsai) (1.24.3)\n","Requirement already satisfied: blis\u003c0.8.0,\u003e=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.0-\u003espacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (0.7.8)\n","Requirement already satisfied: confection\u003c1.0.0,\u003e=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.0-\u003espacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (0.0.3)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer\u003c0.5.0,\u003e=0.3.0-\u003espacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (7.1.2)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-\u003espacy\u003c4-\u003efastai\u003e=2.7.9-\u003etsai) (2.0.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003efastai\u003e=2.7.9-\u003etsai) (0.11.0)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003efastai\u003e=2.7.9-\u003etsai) (2.8.2)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003efastai\u003e=2.7.9-\u003etsai) (1.4.4)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.1-\u003ematplotlib-\u003efastai\u003e=2.7.9-\u003etsai) (1.15.0)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003efastai\u003e=2.7.9-\u003etsai) (2022.4)\n","Installing collected packages: pyts, tsai\n","Successfully installed pyts-0.12.0 tsai-0.3.2\n","Downloading...\n","From: https://drive.google.com/uc?id=1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","To: /content/ThaiDepression.zip\n","100% 41.1k/41.1k [00:00\u003c00:00, 50.1MB/s]\n","Archive:  /content/ThaiDepression.zip\n","  inflating: ThaiDepression/AHB_01.csv  \n","  inflating: ThaiDepression/AHB_02.csv  \n","  inflating: ThaiDepression/AHB_03.csv  \n","  inflating: ThaiDepression/AHB_04.csv  \n","  inflating: ThaiDepression/AHB_05.csv  \n","  inflating: ThaiDepression/AHB_06.csv  \n","  inflating: ThaiDepression/AHB_07.csv  \n","  inflating: ThaiDepression/AHB_08.csv  \n","  inflating: ThaiDepression/AHB_09.csv  \n","  inflating: ThaiDepression/AHB_10.csv  \n","  inflating: ThaiDepression/AHB_11.csv  \n","  inflating: ThaiDepression/AHB_12.csv  \n","  inflating: ThaiDepression/AHB_13.csv  \n","  inflating: ThaiDepression/All_AHB.csv  \n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 25.3 MB/s eta 0:00:48tcmalloc: large alloc 1147494400 bytes == 0x3a410000 @  0x7eff79383615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████▌               | 1055.7 MB 1.4 MB/s eta 0:11:53tcmalloc: large alloc 1434370048 bytes == 0x7ea66000 @  0x7eff79383615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:10:08tcmalloc: large alloc 1792966656 bytes == 0x3898000 @  0x7eff79383615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.3 MB/s eta 0:04:25tcmalloc: large alloc 2241208320 bytes == 0x6e680000 @  0x7eff79383615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf3fe2000 @  0x7eff793821e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n","tcmalloc: large alloc 2551685120 bytes == 0x1e1f60000 @  0x7eff79383615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n","\u001b[K     |████████████████████████████████| 2041.3 MB 6.8 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 47.6 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: pillow\u003e=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["! pip install tsai\n","! gdown 1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","! unzip /content/ThaiDepression.zip\n","! pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XT_fH0lfhPny"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from numpy import array\n","from math import sqrt\n","from numpy import mean\n","from pandas import DataFrame\n","from pandas import concat\n","from pandas import read_csv\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n","import json\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gudPXRtug51K"},"outputs":[],"source":["file_list = os.listdir('ThaiDepression')\n","file_list.sort()\n","df_list = []\n","for i in range(14):\n","    df_list.append(pd.read_csv('ThaiDepression/' + file_list[i], index_col=0))\n","    \n","    \n","class NumpyEncoder(json.JSONEncoder):\n","    \"\"\" Special json encoder for numpy types \"\"\"\n","    def default(self, obj):\n","        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n","                            np.int16, np.int32, np.int64, np.uint8,\n","                            np.uint16, np.uint32, np.uint64)):\n","            return int(obj)\n","        elif isinstance(obj, (np.float_, np.float16, np.float32,\n","                              np.float64)):\n","            return float(obj)\n","        elif isinstance(obj, (np.ndarray,)):\n","            return obj.tolist()\n","        return json.JSONEncoder.default(self, obj)\n","\n","# split a univariate sequence into samples\n","def uni_split_sequence(sequence, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the sequence\n","        if end_ix \u003e len(sequence)-1:\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","        X.append([seq_x])\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","\n","    # split a multivariate sequence into samples\n","def multi_split_sequences(sequences, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequences)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the dataset\n","        if end_ix \u003e len(sequences):\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","def get_scaler(scaler):\n","    scalers = {\n","        \"minmax\": MinMaxScaler,\n","        \"standard\": StandardScaler,\n","        \"maxabs\": MaxAbsScaler,\n","        \"robust\": RobustScaler,\n","    }\n","    return scalers.get(scaler.lower())()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HqCqoJtDePL7Xz7WjYU-64fAUIDJ2jmh"},"id":"GpaAkaxtWH5Z","outputId":"8903339c-4d4f-4f73-a581-2de52da9a583"},"outputs":[],"source":["# define scope of configs\n","AHB_list = [10]\n","n_steps = [1]\n","mul_uni = ['uni','mul']\n","n_layers = [2, 3, 4]\n","dropouts = [0.1, 0.2, 0.4]\n","fc_dropouts = [0.0, 0.2, 0.4]\n","d_models = [128, 256, 512]\n","d_ffs = [256, 512, 1024]\n","epoches = [10, 25, 50, 100]\n","\n","count = 1\n","performance_json = []\n","for g in AHB_list:\n","    for i in n_steps:\n","        for j in n_layers:\n","            for c in dropouts:\n","                  for d in fc_dropouts:\n","                        for e in d_models:\n","                              for h in d_ffs:\n","                                  for f in mul_uni:\n","                                      for k in epoches:\n","                                          print('PROGRESS: [ ' + str(count) + ' / ' + str(len(AHB_list)*len(n_steps)*len(mul_uni)*len(n_layers)*len(dropouts) \\\n","                                          *len(fc_dropouts)*len(d_models)*len(d_ffs)*len(epoches)) + ' ]')\n","                                          if f == 'uni':\n","                                              if g == 13:\n","                                                  raw_seq = list(df_list[g]['Country_Level'])\n","                                                  ahb = 'Country_Level'\n","                                              else:    \n","                                                  raw_seq = list(df_list[g]['AHB_'+str(g+1)])\n","                                                  ahb = 'AHB_'+str(g+1)\n","                                              n_features = 1\n","                                              scaler = get_scaler('minmax')\n","                                              raw_seq_arr = scaler.fit_transform(np.array(raw_seq).reshape(len(raw_seq),-1)).reshape((len(raw_seq)))\n","                                              X, y = uni_split_sequence(raw_seq_arr, i)\n","                                          if f == 'mul':\n","                                              if g == 13:\n","                                                  raw_seq = list(df_list[13].drop(df_list[13].columns[:77], axis=1).values)\n","                                                  ahb = 'Country_Level'\n","                                                  scaler_y = get_scaler('minmax')\n","                                                  scaler_y.fit(np.array(df_list[13]['Country_Level']).reshape(len(df_list[13]['Country_Level']),-1))\n","                                              else:    \n","                                                  raw_seq = list(df_list[g].drop(['Country_Level'], axis=1).values)\n","                                                  ahb = 'AHB_'+str(g+1)\n","                                                  scaler_y = get_scaler('minmax')\n","                                                  scaler_y.fit(np.array(df_list[g]['AHB_'+str(g+1)]).reshape(len(df_list[13]['AHB_'+str(g+1)]),-1))\n","                                              n_features = len(raw_seq[0])-1\n","                                              scaler = get_scaler('minmax')\n","                                              raw_seq_arr = scaler.fit_transform(np.array(raw_seq))\n","                                              X, y = multi_split_sequences(raw_seq_arr, i)\n","                                              \n","                                          from tsai.all import *\n","                                          splits = TimeSplitter(int(len(y)*0.1))(y) \n","                                          batch_tfms = TSStandardize()\n","                                          fcst = TSForecaster(X, y, splits=splits, path='models', batch_tfms=batch_tfms, bs=16, arch=TST, metrics=mse, \n","                                                              arch_config={'n_layers':j, 'dropout':c, 'fc_dropout':d, 'd_model':e, 'd_ff':h})\n","                                          fcst.fit_one_cycle(k, 1e-3)\n","                                          fcst.export(\"fcst.pkl\")\n","\n","                                          from tsai.inference import load_learner\n","                                          fcst = load_learner(\"models/fcst.pkl\", cpu=False)\n","                                          raw_preds, target, preds = fcst.get_X_preds(X[splits[1]], y[splits[1]])\n","                                          print(raw_preds.shape)\n","                                          mae = mean_absolute_error(target, preds)\n","                                          mse = mean_squared_error(target, preds)\n","                                          rmse = mean_squared_error(target, preds, squared = False)\n","                                          mape = mean_absolute_percentage_error(target, preds)\n","\n","\n","                                          if f == 'uni':\n","                                              preds_inverse = scaler.inverse_transform(preds)\n","                                              target_inverse = scaler.inverse_transform(target.reshape((len(target),-1)))\n","                                          if f == 'mul':\n","                                              preds_inverse = scaler_y.inverse_transform(preds)\n","                                              target_inverse = scaler_y.inverse_transform(target.reshape((len(target),-1)))\n","\n","                                          mae_inverse = mean_absolute_error(target_inverse, preds_inverse)\n","                                          mse_inverse = mean_squared_error(target_inverse, preds_inverse)\n","                                          rmse_inverse = mean_squared_error(target_inverse, preds_inverse, squared = False)\n","                                          mape_inverse = mean_absolute_percentage_error(target_inverse, preds_inverse)\n","                                          \n","                                          performance_json.append({'model': 'TST', 'AHB_number': ahb, 'Multi_Uni': f, 'epoch': k, \n","                                                      'n_layers':j, 'dropout':c, 'fc_dropout':d, 'd_model':e, 'd_ff':h, 'n_steps': i, 'MAE_normalize': float(mae), \n","                                                      'MSE_normalize': float(mse), 'RMSE_normalize': float(rmse), 'MAPE_normalize': float(mape), \n","                                                      'MAE': float(mae_inverse), 'MSE': float(mse_inverse), 'RMSE': float(rmse_inverse), 'MAPE': float(mape_inverse)})\n","\n","                                          json_formatted_str = json.dumps(performance_json[-1], indent=2, cls=NumpyEncoder)\n","                                          print(json_formatted_str)\n","                                          import psutil \n","                                          print('Percent CPU Usage: ' + str(psutil.cpu_percent()))\n","                                          print('Percent Ram Usage: ' + str(psutil.virtual_memory()[2]))\n","                                          from datetime import datetime, timezone, timedelta\n","                                          timezone_offset = 7.0  # Bangkok Time (UTC+07:00) \n","                                          tzinfo = timezone(timedelta(hours=timezone_offset))\n","                                          print(datetime.now(tzinfo))\n","                                          \n","                                          count = count + 1\n","                                          "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwg2MpMqY9-S"},"outputs":[],"source":["name = \"all_performance_TST_1nsteps_AHB11\"\n","json.dump(performance_json, open(name + \".json\",\"w\"))\n","df_json = pd.read_json('/content/' + name + '.json')\n","df_json.to_csv('/content/' + name + '.csv', index=False)\n","#! cp /content/all_performance_TST_AHB1.json /content/drive/MyDrive/Depression\n","! cp /content/all_performance_TST_1nsteps_AHB11.csv /content/drive/MyDrive/Depression"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPrWIc5yMr6li7Ecw2NpKfV","collapsed_sections":[],"mount_file_id":"1SBkJvKR32Hnrp6_D6BbjjAg3iNwMk4vk","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}