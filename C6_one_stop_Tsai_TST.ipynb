{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232586,"status":"ok","timestamp":1665748656443,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"},"user_tz":-420},"id":"45kEgxlPJkhU","outputId":"e408219c-608e-414d-e7be-3a01bdd00978"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tsai\n","  Downloading tsai-0.3.2-py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.8 in /usr/local/lib/python3.7/dist-packages (from tsai) (5.4.8)\n","Collecting pyts>=0.12.0\n","  Downloading pyts-0.12.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 48.8 MB/s \n","\u001b[?25hRequirement already satisfied: imbalanced-learn>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tsai) (0.8.1)\n","Requirement already satisfied: fastai>=2.7.9 in /usr/local/lib/python3.7/dist-packages (from tsai) (2.7.9)\n","Requirement already satisfied: torch<1.14,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from tsai) (1.12.1+cu113)\n","Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (7.1.2)\n","Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (0.0.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (2.23.0)\n","Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (3.4.1)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (21.1.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (1.7.3)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (0.13.1+cu113)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (1.0.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (21.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (3.2.2)\n","Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (1.5.27)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (6.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai>=2.7.9->tsai) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn>=0.8.0->tsai) (1.2.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn>=0.8.0->tsai) (1.21.6)\n","Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts>=0.12.0->tsai) (0.56.2)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts>=0.12.0->tsai) (0.39.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts>=0.12.0->tsai) (5.0.0)\n","Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts>=0.12.0->tsai) (57.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.7.9->tsai) (3.1.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (8.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (3.0.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (2.11.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (2.0.8)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (3.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (2.0.6)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (1.0.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (4.64.1)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (4.1.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (1.0.8)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (0.6.2)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (0.4.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (2.4.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (0.10.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (1.9.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.7.9->tsai) (3.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai>=2.7.9->tsai) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai>=2.7.9->tsai) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4->fastai>=2.7.9->tsai) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.7.9->tsai) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.7.9->tsai) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.7.9->tsai) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.7.9->tsai) (2.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.7.9->tsai) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.7.9->tsai) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai>=2.7.9->tsai) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4->fastai>=2.7.9->tsai) (2.0.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.7.9->tsai) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.7.9->tsai) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.7.9->tsai) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai>=2.7.9->tsai) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai>=2.7.9->tsai) (2022.4)\n","Installing collected packages: pyts, tsai\n","Successfully installed pyts-0.12.0 tsai-0.3.2\n","Downloading...\n","From: https://drive.google.com/uc?id=1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","To: /content/ThaiDepression.zip\n","100% 41.1k/41.1k [00:00<00:00, 47.7MB/s]\n","Archive:  /content/ThaiDepression.zip\n","  inflating: ThaiDepression/AHB_01.csv  \n","  inflating: ThaiDepression/AHB_02.csv  \n","  inflating: ThaiDepression/AHB_03.csv  \n","  inflating: ThaiDepression/AHB_04.csv  \n","  inflating: ThaiDepression/AHB_05.csv  \n","  inflating: ThaiDepression/AHB_06.csv  \n","  inflating: ThaiDepression/AHB_07.csv  \n","  inflating: ThaiDepression/AHB_08.csv  \n","  inflating: ThaiDepression/AHB_09.csv  \n","  inflating: ThaiDepression/AHB_10.csv  \n","  inflating: ThaiDepression/AHB_11.csv  \n","  inflating: ThaiDepression/AHB_12.csv  \n","  inflating: ThaiDepression/AHB_13.csv  \n","  inflating: ThaiDepression/All_AHB.csv  \n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.6 MB/s eta 0:12:31tcmalloc: large alloc 1147494400 bytes == 0x3a08a000 @  0x7f5c24149615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |████████████████▌               | 1055.7 MB 1.3 MB/s eta 0:12:32tcmalloc: large alloc 1434370048 bytes == 0x7e6e0000 @  0x7f5c24149615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:41tcmalloc: large alloc 1792966656 bytes == 0x3512000 @  0x7f5c24149615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.4 MB/s eta 0:04:07tcmalloc: large alloc 2241208320 bytes == 0x6e2fa000 @  0x7f5c24149615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf3c5c000 @  0x7f5c241481e7 0x4b2150 0x4b21dc 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5\n","tcmalloc: large alloc 2551685120 bytes == 0x1e1bda000 @  0x7f5c24149615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x4ba899 0x4d29f9\n","\u001b[K     |████████████████████████████████| 2041.3 MB 6.8 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 1.5 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["! pip install tsai\n","! gdown 1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","! unzip /content/ThaiDepression.zip\n","! pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XT_fH0lfhPny"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from numpy import array\n","from math import sqrt\n","from numpy import mean\n","from pandas import DataFrame\n","from pandas import concat\n","from pandas import read_csv\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n","import json\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gudPXRtug51K"},"outputs":[],"source":["file_list = os.listdir('ThaiDepression')\n","file_list.sort()\n","df_list = []\n","for i in range(14):\n","    df_list.append(pd.read_csv('ThaiDepression/' + file_list[i], index_col=0))\n","    \n","    \n","class NumpyEncoder(json.JSONEncoder):\n","    \"\"\" Special json encoder for numpy types \"\"\"\n","    def default(self, obj):\n","        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n","                            np.int16, np.int32, np.int64, np.uint8,\n","                            np.uint16, np.uint32, np.uint64)):\n","            return int(obj)\n","        elif isinstance(obj, (np.float_, np.float16, np.float32,\n","                              np.float64)):\n","            return float(obj)\n","        elif isinstance(obj, (np.ndarray,)):\n","            return obj.tolist()\n","        return json.JSONEncoder.default(self, obj)\n","\n","# split a univariate sequence into samples\n","def uni_split_sequence(sequence, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the sequence\n","        if end_ix > len(sequence)-1:\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","        X.append([seq_x])\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","\n","    # split a multivariate sequence into samples\n","def multi_split_sequences(sequences, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequences)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the dataset\n","        if end_ix > len(sequences):\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","def get_scaler(scaler):\n","    scalers = {\n","        \"minmax\": MinMaxScaler,\n","        \"standard\": StandardScaler,\n","        \"maxabs\": MaxAbsScaler,\n","        \"robust\": RobustScaler,\n","    }\n","    return scalers.get(scaler.lower())()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1-T3U9nPH2zUQlnCKgdIPwBAPv7E4Us7u"},"id":"GpaAkaxtWH5Z","outputId":"48e097eb-6004-4198-bd7c-0b4ca1c16351"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# define scope of configs\n","AHB_list = [6]\n","n_steps = [1]\n","mul_uni = ['uni','mul']\n","n_layers = [2, 3, 4]\n","dropouts = [0.1, 0.2, 0.4]\n","fc_dropouts = [0.0, 0.2, 0.4]\n","d_models = [128, 256, 512]\n","d_ffs = [256, 512, 1024]\n","epoches = [10, 25, 50, 100]\n","\n","count = 1\n","performance_json = []\n","for g in AHB_list:\n","    for i in n_steps:\n","        for j in n_layers:\n","            for c in dropouts:\n","                  for d in fc_dropouts:\n","                        for e in d_models:\n","                              for h in d_ffs:\n","                                  for f in mul_uni:\n","                                      for k in epoches:\n","                                          print('PROGRESS: [ ' + str(count) + ' / ' + str(len(AHB_list)*len(n_steps)*len(mul_uni)*len(n_layers)*len(dropouts) \\\n","                                          *len(fc_dropouts)*len(d_models)*len(d_ffs)*len(epoches)) + ' ]')\n","                                          if f == 'uni':\n","                                              if g == 13:\n","                                                  raw_seq = list(df_list[g]['Country_Level'])\n","                                                  ahb = 'Country_Level'\n","                                              else:    \n","                                                  raw_seq = list(df_list[g]['AHB_'+str(g+1)])\n","                                                  ahb = 'AHB_'+str(g+1)\n","                                              n_features = 1\n","                                              scaler = get_scaler('minmax')\n","                                              raw_seq_arr = scaler.fit_transform(np.array(raw_seq).reshape(len(raw_seq),-1)).reshape((len(raw_seq)))\n","                                              X, y = uni_split_sequence(raw_seq_arr, i)\n","                                          if f == 'mul':\n","                                              if g == 13:\n","                                                  raw_seq = list(df_list[13].drop(df_list[13].columns[:77], axis=1).values)\n","                                                  ahb = 'Country_Level'\n","                                                  scaler_y = get_scaler('minmax')\n","                                                  scaler_y.fit(np.array(df_list[13]['Country_Level']).reshape(len(df_list[13]['Country_Level']),-1))\n","                                              else:    \n","                                                  raw_seq = list(df_list[g].drop(['Country_Level'], axis=1).values)\n","                                                  ahb = 'AHB_'+str(g+1)\n","                                                  scaler_y = get_scaler('minmax')\n","                                                  scaler_y.fit(np.array(df_list[g]['AHB_'+str(g+1)]).reshape(len(df_list[13]['AHB_'+str(g+1)]),-1))\n","                                              n_features = len(raw_seq[0])-1\n","                                              scaler = get_scaler('minmax')\n","                                              raw_seq_arr = scaler.fit_transform(np.array(raw_seq))\n","                                              X, y = multi_split_sequences(raw_seq_arr, i)\n","                                              \n","                                          from tsai.all import *\n","                                          splits = TimeSplitter(int(len(y)*0.1))(y) \n","                                          batch_tfms = TSStandardize()\n","                                          fcst = TSForecaster(X, y, splits=splits, path='models', batch_tfms=batch_tfms, bs=16, arch=TST, metrics=mse, \n","                                                              arch_config={'n_layers':j, 'dropout':c, 'fc_dropout':d, 'd_model':e, 'd_ff':h})\n","                                          fcst.fit_one_cycle(k, 1e-3)\n","                                          fcst.export(\"fcst.pkl\")\n","\n","                                          from tsai.inference import load_learner\n","                                          fcst = load_learner(\"models/fcst.pkl\", cpu=False)\n","                                          raw_preds, target, preds = fcst.get_X_preds(X[splits[1]], y[splits[1]])\n","                                          print(raw_preds.shape)\n","                                          mae = mean_absolute_error(target, preds)\n","                                          mse = mean_squared_error(target, preds)\n","                                          rmse = mean_squared_error(target, preds, squared = False)\n","                                          mape = mean_absolute_percentage_error(target, preds)\n","\n","\n","                                          if f == 'uni':\n","                                              preds_inverse = scaler.inverse_transform(preds)\n","                                              target_inverse = scaler.inverse_transform(target.reshape((len(target),-1)))\n","                                          if f == 'mul':\n","                                              preds_inverse = scaler_y.inverse_transform(preds)\n","                                              target_inverse = scaler_y.inverse_transform(target.reshape((len(target),-1)))\n","\n","                                          mae_inverse = mean_absolute_error(target_inverse, preds_inverse)\n","                                          mse_inverse = mean_squared_error(target_inverse, preds_inverse)\n","                                          rmse_inverse = mean_squared_error(target_inverse, preds_inverse, squared = False)\n","                                          mape_inverse = mean_absolute_percentage_error(target_inverse, preds_inverse)\n","                                          \n","                                          performance_json.append({'model': 'TST', 'AHB_number': ahb, 'Multi_Uni': f, 'epoch': k, \n","                                                      'n_layers':j, 'dropout':c, 'fc_dropout':d, 'd_model':e, 'd_ff':h, 'n_steps': i, 'MAE_normalize': float(mae), \n","                                                      'MSE_normalize': float(mse), 'RMSE_normalize': float(rmse), 'MAPE_normalize': float(mape), \n","                                                      'MAE': float(mae_inverse), 'MSE': float(mse_inverse), 'RMSE': float(rmse_inverse), 'MAPE': float(mape_inverse)})\n","\n","                                          json_formatted_str = json.dumps(performance_json[-1], indent=2, cls=NumpyEncoder)\n","                                          print(json_formatted_str)\n","                                          import psutil \n","                                          print('Percent CPU Usage: ' + str(psutil.cpu_percent()))\n","                                          print('Percent Ram Usage: ' + str(psutil.virtual_memory()[2]))\n","                                          from datetime import datetime, timezone, timedelta\n","                                          timezone_offset = 7.0  # Bangkok Time (UTC+07:00) \n","                                          tzinfo = timezone(timedelta(hours=timezone_offset))\n","                                          print(datetime.now(tzinfo))\n","                                          \n","                                          count = count + 1\n","                                          "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwg2MpMqY9-S"},"outputs":[],"source":["name = \"all_performance_TST_1nsteps_AHB7\"\n","json.dump(performance_json, open(name + \".json\",\"w\"))\n","df_json = pd.read_json('/content/' + name + '.json')\n","df_json.to_csv('/content/' + name + '.csv', index=False)\n","#! cp /content/all_performance_TST_AHB1.json /content/drive/MyDrive/Depression\n","! cp /content/all_performance_TST_1nsteps_AHB7.csv /content/drive/MyDrive/Depression"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"mount_file_id":"18M9sO2ldwnSxvOpbvuv_ncLjLYL1fZIl","authorship_tag":"ABX9TyOdIZWPidITqJJlP6oP9JK0"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}