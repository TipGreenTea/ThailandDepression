{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UspyHsUMUiwQVaUu2XgTXNBkCUwT-Lz0","authorship_tag":"ABX9TyObtUiAO5RNO9h7CsyAmNe3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! gdown 1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","! unzip /content/ThaiDepression.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v17GRLh1kkW9","executionInfo":{"status":"ok","timestamp":1666893145195,"user_tz":-420,"elapsed":1758,"user":{"displayName":"Pasinpat Vitoochuleechoti","userId":"04423538674438574487"}},"outputId":"b6a5a639-cda7-49c1-d7bb-f533665e4584"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1yEjicXasMGFaALQobQWgsSxQgLEtxruC\n","To: /content/ThaiDepression.zip\n","\r  0% 0.00/41.1k [00:00<?, ?B/s]\r100% 41.1k/41.1k [00:00<00:00, 75.0MB/s]\n","Archive:  /content/ThaiDepression.zip\n","  inflating: ThaiDepression/AHB_01.csv  \n","  inflating: ThaiDepression/AHB_02.csv  \n","  inflating: ThaiDepression/AHB_03.csv  \n","  inflating: ThaiDepression/AHB_04.csv  \n","  inflating: ThaiDepression/AHB_05.csv  \n","  inflating: ThaiDepression/AHB_06.csv  \n","  inflating: ThaiDepression/AHB_07.csv  \n","  inflating: ThaiDepression/AHB_08.csv  \n","  inflating: ThaiDepression/AHB_09.csv  \n","  inflating: ThaiDepression/AHB_10.csv  \n","  inflating: ThaiDepression/AHB_11.csv  \n","  inflating: ThaiDepression/AHB_12.csv  \n","  inflating: ThaiDepression/AHB_13.csv  \n","  inflating: ThaiDepression/All_AHB.csv  \n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2lJ-wrqj4We","outputId":"655b7529-af42-41cb-903c-aee220181025"},"outputs":[{"output_type":"stream","name":"stdout","text":["PROGRESS: [ 12051 / 12600 ]\n","{\n","  \"count\": 12051,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 16,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 38,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.17558324264676178,\n","  \"MSE_normalize\": 0.03137642035766323,\n","  \"RMSE_normalize\": 0.1771339051612176,\n","  \"MAPE_normalize\": 0.1841605065746454,\n","  \"MAE\": 7548.848214285715,\n","  \"MSE\": 57996080.02260045,\n","  \"RMSE\": 7615.515742390692,\n","  \"MAPE\": 0.08061128788814599\n","}\n","Percent CPU Usage: 39.0\n","Percent Ram Usage: 14.1\n","2022-10-28 00:53:39.165959+07:00\n","PROGRESS: [ 12052 / 12600 ]\n","{\n","  \"count\": 12052,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 16,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 32,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.11182916943563681,\n","  \"MSE_normalize\": 0.013174145585783597,\n","  \"RMSE_normalize\": 0.11477868088536128,\n","  \"MAPE_normalize\": 0.11690616561455218,\n","  \"MAE\": 4807.871651785715,\n","  \"MSE\": 24351065.118573867,\n","  \"RMSE\": 4934.679839520885,\n","  \"MAPE\": 0.0512677898976139\n","}\n","Percent CPU Usage: 59.1\n","Percent Ram Usage: 15.7\n","2022-10-28 00:53:51.998490+07:00\n","PROGRESS: [ 12053 / 12600 ]\n","{\n","  \"count\": 12053,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 16,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 38,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.15530624487617986,\n","  \"MSE_normalize\": 0.024666540812171005,\n","  \"RMSE_normalize\": 0.15705585252441567,\n","  \"MAPE_normalize\": 0.16279828767400392,\n","  \"MAE\": 6677.079241071428,\n","  \"MSE\": 45593556.14469691,\n","  \"RMSE\": 6752.300063289317,\n","  \"MAPE\": 0.07128392279751058\n","}\n","Percent CPU Usage: 52.2\n","Percent Ram Usage: 14.0\n","2022-10-28 00:54:06.593094+07:00\n","PROGRESS: [ 12054 / 12600 ]\n","{\n","  \"count\": 12054,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 16,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 33,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.14407157825619782,\n","  \"MSE_normalize\": 0.021476293816874364,\n","  \"RMSE_normalize\": 0.14654792327724867,\n","  \"MAPE_normalize\": 0.15084049311875028,\n","  \"MAE\": 6194.069196428572,\n","  \"MSE\": 39696742.159458704,\n","  \"RMSE\": 6300.535069298377,\n","  \"MAPE\": 0.06609277009767012\n","}\n","Percent CPU Usage: 60.1\n","Percent Ram Usage: 13.0\n","2022-10-28 00:54:19.815533+07:00\n","PROGRESS: [ 12055 / 12600 ]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7b44924950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["{\n","  \"count\": 12055,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 17,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.11909647426482557,\n","  \"MSE_normalize\": 0.014505577340509095,\n","  \"RMSE_normalize\": 0.12043910220733586,\n","  \"MAPE_normalize\": 0.12484258290149845,\n","  \"MAE\": 5120.314732142857,\n","  \"MSE\": 26812083.329118997,\n","  \"RMSE\": 5178.038560026277,\n","  \"MAPE\": 0.05466417887573636\n","}\n","Percent CPU Usage: 61.4\n","Percent Ram Usage: 13.0\n","2022-10-28 00:54:24.803924+07:00\n","PROGRESS: [ 12056 / 12600 ]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7b439744d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["{\n","  \"count\": 12056,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 42,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.06937775369249019,\n","  \"MSE_normalize\": 0.005247314112970276,\n","  \"RMSE_normalize\": 0.07243834697844972,\n","  \"MAPE_normalize\": 0.0723595246584375,\n","  \"MAE\": 2982.754464285714,\n","  \"MSE\": 9699101.920846118,\n","  \"RMSE\": 3114.338119223107,\n","  \"MAPE\": 0.03177391935780425\n","}\n","Percent CPU Usage: 67.1\n","Percent Ram Usage: 13.0\n","2022-10-28 00:54:33.696426+07:00\n","PROGRESS: [ 12057 / 12600 ]\n","{\n","  \"count\": 12057,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 39,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09462560853835462,\n","  \"MSE_normalize\": 0.009306024827111134,\n","  \"RMSE_normalize\": 0.09646773982586683,\n","  \"MAPE_normalize\": 0.09903225239788127,\n","  \"MAE\": 4068.237723214286,\n","  \"MSE\": 17201230.687665664,\n","  \"RMSE\": 4147.4366405848405,\n","  \"MAPE\": 0.04340195319079189\n","}\n","Percent CPU Usage: 62.3\n","Percent Ram Usage: 12.8\n","2022-10-28 00:54:40.865216+07:00\n","PROGRESS: [ 12058 / 12600 ]\n","{\n","  \"count\": 12058,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 25,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.0925882792051855,\n","  \"MSE_normalize\": 0.009006580778815719,\n","  \"RMSE_normalize\": 0.094903007216925,\n","  \"MAPE_normalize\": 0.09681269677785762,\n","  \"MAE\": 3980.6462053571427,\n","  \"MSE\": 16647734.280979697,\n","  \"RMSE\": 4080.163511549469,\n","  \"MAPE\": 0.04245079902677583\n","}\n","Percent CPU Usage: 55.1\n","Percent Ram Usage: 12.8\n","2022-10-28 00:54:47.348456+07:00\n","PROGRESS: [ 12059 / 12600 ]\n","{\n","  \"count\": 12059,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 34,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09519468814182229,\n","  \"MSE_normalize\": 0.009433144138935104,\n","  \"RMSE_normalize\": 0.09712437458709891,\n","  \"MAPE_normalize\": 0.09961405265002991,\n","  \"MAE\": 4092.706473214286,\n","  \"MSE\": 17436219.936008994,\n","  \"RMSE\": 4175.669998456415,\n","  \"MAPE\": 0.043660367753765465\n","}\n","Percent CPU Usage: 50.0\n","Percent Ram Usage: 12.7\n","2022-10-28 00:54:54.407929+07:00\n","PROGRESS: [ 12060 / 12600 ]\n","{\n","  \"count\": 12060,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 27,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09018238029357313,\n","  \"MSE_normalize\": 0.00859946354937105,\n","  \"RMSE_normalize\": 0.0927332925619006,\n","  \"MAPE_normalize\": 0.09425074759739963,\n","  \"MAE\": 3877.2131696428573,\n","  \"MSE\": 15895247.991830004,\n","  \"RMSE\": 3986.8844969261404,\n","  \"MAPE\": 0.041338930303422505\n","}\n","Percent CPU Usage: 58.5\n","Percent Ram Usage: 12.7\n","2022-10-28 00:54:59.645923+07:00\n","PROGRESS: [ 12061 / 12600 ]\n","{\n","  \"count\": 12061,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 46,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08144192963886208,\n","  \"MSE_normalize\": 0.007008477412245891,\n","  \"RMSE_normalize\": 0.08371664955220014,\n","  \"MAPE_normalize\": 0.08512087404367198,\n","  \"MAE\": 3501.4308035714284,\n","  \"MSE\": 12954440.94853864,\n","  \"RMSE\": 3599.227826706534,\n","  \"MAPE\": 0.037333263741529295\n","}\n","Percent CPU Usage: 56.4\n","Percent Ram Usage: 12.6\n","2022-10-28 00:55:05.444098+07:00\n","PROGRESS: [ 12062 / 12600 ]\n","{\n","  \"count\": 12062,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 72,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.0856213647557662,\n","  \"MSE_normalize\": 0.007792240033656575,\n","  \"RMSE_normalize\": 0.08827366557278889,\n","  \"MAPE_normalize\": 0.0894501131793931,\n","  \"MAE\": 3681.1160714285716,\n","  \"MSE\": 14403136.389979767,\n","  \"RMSE\": 3795.146425367507,\n","  \"MAPE\": 0.03924166911783485\n","}\n","Percent CPU Usage: 61.9\n","Percent Ram Usage: 12.6\n","2022-10-28 00:55:10.897802+07:00\n","PROGRESS: [ 12063 / 12600 ]\n","{\n","  \"count\": 12063,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 34,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.19797425538349098,\n","  \"MSE_normalize\": 0.03961209429184516,\n","  \"RMSE_normalize\": 0.19902787315309672,\n","  \"MAPE_normalize\": 0.20785387670421557,\n","  \"MAE\": 8511.50669642857,\n","  \"MSE\": 73218911.60731724,\n","  \"RMSE\": 8556.804988272039,\n","  \"MAPE\": 0.09093095754129711\n","}\n","Percent CPU Usage: 56.5\n","Percent Ram Usage: 12.6\n","2022-10-28 00:55:15.384189+07:00\n","PROGRESS: [ 12064 / 12600 ]\n","{\n","  \"count\": 12064,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 21,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.12579288580635564,\n","  \"MSE_normalize\": 0.01635143251864896,\n","  \"RMSE_normalize\": 0.12787271999394148,\n","  \"MAPE_normalize\": 0.13171930816707364,\n","  \"MAE\": 5408.212053571428,\n","  \"MSE\": 30223937.49541364,\n","  \"RMSE\": 5497.630170847584,\n","  \"MAPE\": 0.057710515065127956\n","}\n","Percent CPU Usage: 54.8\n","Percent Ram Usage: 12.5\n","2022-10-28 00:55:20.556433+07:00\n","PROGRESS: [ 12065 / 12600 ]\n","{\n","  \"count\": 12065,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 45,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.2064235458634235,\n","  \"MSE_normalize\": 0.043046561368762934,\n","  \"RMSE_normalize\": 0.20747665258713555,\n","  \"MAPE_normalize\": 0.21674055362478264,\n","  \"MAE\": 8874.76450892857,\n","  \"MSE\": 79567127.55994524,\n","  \"RMSE\": 8920.040782414912,\n","  \"MAPE\": 0.0948147500956381\n","}\n","Percent CPU Usage: 57.2\n","Percent Ram Usage: 12.5\n","2022-10-28 00:55:25.153784+07:00\n","PROGRESS: [ 12066 / 12600 ]\n","{\n","  \"count\": 12066,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 27,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.07485317260074563,\n","  \"MSE_normalize\": 0.006160743831073981,\n","  \"RMSE_normalize\": 0.07849040598107504,\n","  \"MAPE_normalize\": 0.07802954073488282,\n","  \"MAE\": 3218.1618303571427,\n","  \"MSE\": 11387504.837759832,\n","  \"RMSE\": 3374.5377220828086,\n","  \"MAPE\": 0.034273861744743526\n","}\n","Percent CPU Usage: 56.1\n","Percent Ram Usage: 12.5\n","2022-10-28 00:55:30.488982+07:00\n","PROGRESS: [ 12067 / 12600 ]\n","{\n","  \"count\": 12067,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 127,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.13304436985983115,\n","  \"MSE_normalize\": 0.018045761168384192,\n","  \"RMSE_normalize\": 0.1343345122013855,\n","  \"MAPE_normalize\": 0.1395146217259298,\n","  \"MAE\": 5719.975446428572,\n","  \"MSE\": 33355730.72209821,\n","  \"RMSE\": 5775.442036943857,\n","  \"MAPE\": 0.06107589727947616\n","}\n","Percent CPU Usage: 59.5\n","Percent Ram Usage: 12.5\n","2022-10-28 00:55:35.334270+07:00\n","PROGRESS: [ 12068 / 12600 ]\n","{\n","  \"count\": 12068,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 25,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08112807712432264,\n","  \"MSE_normalize\": 0.007113147131411667,\n","  \"RMSE_normalize\": 0.08433947552250765,\n","  \"MAPE_normalize\": 0.08466047362293931,\n","  \"MAE\": 3487.940848214286,\n","  \"MSE\": 13147939.011308938,\n","  \"RMSE\": 3626.0086888077003,\n","  \"MAPE\": 0.03716416755901166\n","}\n","Percent CPU Usage: 54.0\n","Percent Ram Usage: 12.5\n","2022-10-28 00:55:40.470506+07:00\n","PROGRESS: [ 12069 / 12600 ]\n","{\n","  \"count\": 12069,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 21,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09630919281973105,\n","  \"MSE_normalize\": 0.009655768799105985,\n","  \"RMSE_normalize\": 0.09826377154936597,\n","  \"MAPE_normalize\": 0.10077976590210168,\n","  \"MAE\": 4140.620535714285,\n","  \"MSE\": 17847698.297816683,\n","  \"RMSE\": 4224.653630514184,\n","  \"MAPE\": 0.04417140885047869\n","}\n","Percent CPU Usage: 54.7\n","Percent Ram Usage: 12.5\n","2022-10-28 00:55:52.039412+07:00\n","PROGRESS: [ 12070 / 12600 ]\n","{\n","  \"count\": 12070,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 45,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.06953732384150316,\n","  \"MSE_normalize\": 0.005267477366889749,\n","  \"RMSE_normalize\": 0.07257738881283722,\n","  \"MAPE_normalize\": 0.07252951414578736,\n","  \"MAE\": 2989.6149553571427,\n","  \"MSE\": 9736379.76418631,\n","  \"RMSE\": 3120.3172537718515,\n","  \"MAPE\": 0.03184767306923129\n","}\n","Percent CPU Usage: 67.9\n","Percent Ram Usage: 12.4\n","2022-10-28 00:56:10.343536+07:00\n","PROGRESS: [ 12071 / 12600 ]\n","{\n","  \"count\": 12071,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 21,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09010510712909646,\n","  \"MSE_normalize\": 0.008514541819354658,\n","  \"RMSE_normalize\": 0.09227427495978853,\n","  \"MAPE_normalize\": 0.09422981813710922,\n","  \"MAE\": 3873.887276785714,\n","  \"MSE\": 15738250.08095877,\n","  \"RMSE\": 3967.146339745834,\n","  \"MAPE\": 0.041314897337501315\n","}\n","Percent CPU Usage: 50.6\n","Percent Ram Usage: 12.5\n","2022-10-28 00:56:23.367354+07:00\n","PROGRESS: [ 12072 / 12600 ]\n","{\n","  \"count\": 12072,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 25,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.07077198296832986,\n","  \"MSE_normalize\": 0.005461738832297572,\n","  \"RMSE_normalize\": 0.07390357793975588,\n","  \"MAPE_normalize\": 0.07381255566143406,\n","  \"MAE\": 3042.699776785714,\n","  \"MSE\": 10095464.53207833,\n","  \"RMSE\": 3177.336074776845,\n","  \"MAPE\": 0.03241227306633656\n","}\n","Percent CPU Usage: 58.5\n","Percent Ram Usage: 12.7\n","2022-10-28 00:56:36.429167+07:00\n","PROGRESS: [ 12073 / 12600 ]\n","{\n","  \"count\": 12073,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 39,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08991767606612562,\n","  \"MSE_normalize\": 0.008474885448495308,\n","  \"RMSE_normalize\": 0.09205914103713606,\n","  \"MAPE_normalize\": 0.09403759159957303,\n","  \"MAE\": 3865.828125,\n","  \"MSE\": 15664944.585902618,\n","  \"RMSE\": 3957.896484990811,\n","  \"MAPE\": 0.04122967006813789\n","}\n","Percent CPU Usage: 51.0\n","Percent Ram Usage: 12.6\n","2022-10-28 00:56:49.074035+07:00\n","PROGRESS: [ 12074 / 12600 ]\n","{\n","  \"count\": 12074,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 28,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08613510570403456,\n","  \"MSE_normalize\": 0.007853585985977112,\n","  \"RMSE_normalize\": 0.08862046031237432,\n","  \"MAPE_normalize\": 0.09001389379810831,\n","  \"MAE\": 3703.207589285714,\n","  \"MSE\": 14516558.431937078,\n","  \"RMSE\": 3810.06016119655,\n","  \"MAPE\": 0.03948232879587129\n","}\n","Percent CPU Usage: 59.1\n","Percent Ram Usage: 12.5\n","2022-10-28 00:56:59.529622+07:00\n","PROGRESS: [ 12075 / 12600 ]\n","{\n","  \"count\": 12075,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 30,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08164896211501478,\n","  \"MSE_normalize\": 0.007053211016538256,\n","  \"RMSE_normalize\": 0.08398339726718762,\n","  \"MAPE_normalize\": 0.08532900803637745,\n","  \"MAE\": 3510.3337053571427,\n","  \"MSE\": 13037141.328220908,\n","  \"RMSE\": 3610.698177391861,\n","  \"MAPE\": 0.037426616029719965\n","}\n","Percent CPU Usage: 58.7\n","Percent Ram Usage: 12.5\n","2022-10-28 00:57:09.158906+07:00\n","PROGRESS: [ 12076 / 12600 ]\n","{\n","  \"count\": 12076,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 43,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09029555248410308,\n","  \"MSE_normalize\": 0.008601710134164076,\n","  \"RMSE_normalize\": 0.09274540492209885,\n","  \"MAPE_normalize\": 0.0943850131475865,\n","  \"MAE\": 3882.0770089285716,\n","  \"MSE\": 15899385.950762063,\n","  \"RMSE\": 3987.4034095839943,\n","  \"MAPE\": 0.041393841875293116\n","}\n","Percent CPU Usage: 59.7\n","Percent Ram Usage: 12.5\n","2022-10-28 00:57:19.004141+07:00\n","PROGRESS: [ 12077 / 12600 ]\n","{\n","  \"count\": 12077,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 53,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.07648091584491677,\n","  \"MSE_normalize\": 0.006241747963876671,\n","  \"RMSE_normalize\": 0.07900473380675788,\n","  \"MAPE_normalize\": 0.07987910916928105,\n","  \"MAE\": 3288.1428571428573,\n","  \"MSE\": 11537223.506086072,\n","  \"RMSE\": 3396.6488641138744,\n","  \"MAPE\": 0.03504831488877376\n","}\n","Percent CPU Usage: 59.1\n","Percent Ram Usage: 12.5\n","2022-10-28 00:57:27.912407+07:00\n","PROGRESS: [ 12078 / 12600 ]\n","{\n","  \"count\": 12078,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 58,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08876002614034872,\n","  \"MSE_normalize\": 0.008349191437287571,\n","  \"RMSE_normalize\": 0.09137391004705649,\n","  \"MAPE_normalize\": 0.09274888141466908,\n","  \"MAE\": 3816.0613839285716,\n","  \"MSE\": 15432641.880589072,\n","  \"RMSE\": 3928.4401332576103,\n","  \"MAPE\": 0.040683994949424485\n","}\n","Percent CPU Usage: 53.9\n","Percent Ram Usage: 12.5\n","2022-10-28 00:57:38.294120+07:00\n","PROGRESS: [ 12079 / 12600 ]\n","{\n","  \"count\": 12079,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 31,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.12096777911744747,\n","  \"MSE_normalize\": 0.015117211602894347,\n","  \"RMSE_normalize\": 0.12295207034814154,\n","  \"MAPE_normalize\": 0.12667003538477056,\n","  \"MAE\": 5200.764508928572,\n","  \"MSE\": 27942594.29541887,\n","  \"RMSE\": 5286.07550981055,\n","  \"MAPE\": 0.055497474405421125\n","}\n","Percent CPU Usage: 55.6\n","Percent Ram Usage: 12.5\n","2022-10-28 00:57:47.734345+07:00\n","PROGRESS: [ 12080 / 12600 ]\n","{\n","  \"count\": 12080,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 21,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08054269139303427,\n","  \"MSE_normalize\": 0.007082491340329527,\n","  \"RMSE_normalize\": 0.08415753882053305,\n","  \"MAPE_normalize\": 0.08399605344700335,\n","  \"MAE\": 3462.770089285714,\n","  \"MSE\": 13091248.074811658,\n","  \"RMSE\": 3618.1829797305245,\n","  \"MAPE\": 0.036885761478965814\n","}\n","Percent CPU Usage: 53.7\n","Percent Ram Usage: 12.5\n","2022-10-28 00:57:57.177523+07:00\n","PROGRESS: [ 12081 / 12600 ]\n","{\n","  \"count\": 12081,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 29,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.10158671579238295,\n","  \"MSE_normalize\": 0.010810649306435825,\n","  \"RMSE_normalize\": 0.1039742723294365,\n","  \"MAPE_normalize\": 0.10624589901438848,\n","  \"MAE\": 4367.516741071428,\n","  \"MSE\": 19982381.03561837,\n","  \"RMSE\": 4470.165660869669,\n","  \"MAPE\": 0.046581157580971644\n","}\n","Percent CPU Usage: 54.7\n","Percent Ram Usage: 12.5\n","2022-10-28 00:58:05.717255+07:00\n","PROGRESS: [ 12082 / 12600 ]\n","{\n","  \"count\": 12082,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 2,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 25,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.07206571029812896,\n","  \"MSE_normalize\": 0.00579465752263265,\n","  \"RMSE_normalize\": 0.07612264789556818,\n","  \"MAPE_normalize\": 0.07506100888630289,\n","  \"MAE\": 3098.3214285714284,\n","  \"MSE\": 10710838.302420476,\n","  \"RMSE\": 3272.741710312697,\n","  \"MAPE\": 0.03298556227613022\n","}\n","Percent CPU Usage: 54.3\n","Percent Ram Usage: 12.5\n","2022-10-28 00:58:14.938674+07:00\n","PROGRESS: [ 12083 / 12600 ]\n","{\n","  \"count\": 12083,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 28,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.056560813657351376,\n","  \"MSE_normalize\": 0.003695154660991966,\n","  \"RMSE_normalize\": 0.060787783813789145,\n","  \"MAPE_normalize\": 0.05880542552799395,\n","  \"MAE\": 2431.7176339285716,\n","  \"MSE\": 6830116.355843676,\n","  \"RMSE\": 2613.449130142708,\n","  \"MAPE\": 0.025868433438581966\n","}\n","Percent CPU Usage: 66.0\n","Percent Ram Usage: 12.5\n","2022-10-28 00:58:31.090131+07:00\n","PROGRESS: [ 12084 / 12600 ]\n","{\n","  \"count\": 12084,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 31,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09681408673572488,\n","  \"MSE_normalize\": 0.009797039249604836,\n","  \"RMSE_normalize\": 0.09897999418874925,\n","  \"MAPE_normalize\": 0.10127352233235985,\n","  \"MAE\": 4162.327008928572,\n","  \"MSE\": 18108826.003792893,\n","  \"RMSE\": 4255.446628004268,\n","  \"MAPE\": 0.04439633642633607\n","}\n","Percent CPU Usage: 69.9\n","Percent Ram Usage: 12.5\n","2022-10-28 00:58:52.017235+07:00\n","PROGRESS: [ 12085 / 12600 ]\n","{\n","  \"count\": 12085,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 21,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09259658128070779,\n","  \"MSE_normalize\": 0.008982444192309409,\n","  \"RMSE_normalize\": 0.0947757574082603,\n","  \"MAPE_normalize\": 0.09684349641963433,\n","  \"MAE\": 3981.003348214286,\n","  \"MSE\": 16603120.53990827,\n","  \"RMSE\": 4074.692692695766,\n","  \"MAPE\": 0.04245884287741993\n","}\n","Percent CPU Usage: 62.6\n","Percent Ram Usage: 12.8\n","2022-10-28 00:59:07.505002+07:00\n","PROGRESS: [ 12086 / 12600 ]\n","{\n","  \"count\": 12086,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 22,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.09156832452378902,\n","  \"MSE_normalize\": 0.008819430269586623,\n","  \"RMSE_normalize\": 0.09391182177759425,\n","  \"MAPE_normalize\": 0.09573772159160557,\n","  \"MAE\": 3936.7957589285716,\n","  \"MSE\": 16301811.167506622,\n","  \"RMSE\": 4037.5501442714767,\n","  \"MAPE\": 0.04198153496059846\n","}\n","Percent CPU Usage: 58.3\n","Percent Ram Usage: 13.0\n","2022-10-28 00:59:24.626817+07:00\n","PROGRESS: [ 12087 / 12600 ]\n","{\n","  \"count\": 12087,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 23,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.05968951255130715,\n","  \"MSE_normalize\": 0.004022001394898858,\n","  \"RMSE_normalize\": 0.063419250980273,\n","  \"MAPE_normalize\": 0.06213148237330055,\n","  \"MAE\": 2566.229910714286,\n","  \"MSE\": 7434251.364711212,\n","  \"RMSE\": 2726.5823597887543,\n","  \"MAPE\": 0.02731333380848794\n","}\n","Percent CPU Usage: 51.5\n","Percent Ram Usage: 12.9\n","2022-10-28 00:59:41.827310+07:00\n","PROGRESS: [ 12088 / 12600 ]\n","{\n","  \"count\": 12088,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 20,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08186649352359719,\n","  \"MSE_normalize\": 0.007182777166740983,\n","  \"RMSE_normalize\": 0.0847512664609856,\n","  \"MAPE_normalize\": 0.08547846862141946,\n","  \"MAE\": 3519.6886160714284,\n","  \"MSE\": 13276651.87975202,\n","  \"RMSE\": 3643.7140227729205,\n","  \"MAPE\": 0.03751147664188802\n","}\n","Percent CPU Usage: 59.8\n","Percent Ram Usage: 12.8\n","2022-10-28 00:59:56.538109+07:00\n","PROGRESS: [ 12089 / 12600 ]\n","{\n","  \"count\": 12089,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 30,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08559968569496647,\n","  \"MSE_normalize\": 0.007719739438641761,\n","  \"RMSE_normalize\": 0.08786204777172998,\n","  \"MAPE_normalize\": 0.08948605892001589,\n","  \"MAE\": 3680.1875,\n","  \"MSE\": 14269156.338378903,\n","  \"RMSE\": 3777.453684478329,\n","  \"MAPE\": 0.03924296456679632\n","}\n","Percent CPU Usage: 59.1\n","Percent Ram Usage: 12.8\n","2022-10-28 01:00:11.002364+07:00\n","PROGRESS: [ 12090 / 12600 ]\n","{\n","  \"count\": 12090,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 16,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 40,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08188965418556705,\n","  \"MSE_normalize\": 0.007188601226747813,\n","  \"RMSE_normalize\": 0.08478561922135035,\n","  \"MAPE_normalize\": 0.08550112096753033,\n","  \"MAE\": 3520.6808035714284,\n","  \"MSE\": 13287389.381016318,\n","  \"RMSE\": 3645.1871530850535,\n","  \"MAPE\": 0.03752176434686564\n","}\n","Percent CPU Usage: 59.6\n","Percent Ram Usage: 12.7\n","2022-10-28 01:00:25.770699+07:00\n","PROGRESS: [ 12091 / 12600 ]\n","{\n","  \"count\": 12091,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 43,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.07849652354253989,\n","  \"MSE_normalize\": 0.0065501797008629325,\n","  \"RMSE_normalize\": 0.08093318046921752,\n","  \"MAPE_normalize\": 0.0820061742715289,\n","  \"MAE\": 3374.800223214286,\n","  \"MSE\": 12107334.717503134,\n","  \"RMSE\": 3479.5595579761434,\n","  \"MAPE\": 0.03597617425091861\n","}\n","Percent CPU Usage: 56.6\n","Percent Ram Usage: 12.7\n","2022-10-28 01:00:40.586588+07:00\n","PROGRESS: [ 12092 / 12600 ]\n","{\n","  \"count\": 12092,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 32,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 42,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.0913253419318875,\n","  \"MSE_normalize\": 0.008807515529348737,\n","  \"RMSE_normalize\": 0.09384836455340465,\n","  \"MAPE_normalize\": 0.09545451243071064,\n","  \"MAE\": 3926.3493303571427,\n","  \"MSE\": 16279785.92685372,\n","  \"RMSE\": 4034.821672249434,\n","  \"MAPE\": 0.04186458383174121\n","}\n","Percent CPU Usage: 55.7\n","Percent Ram Usage: 12.7\n","2022-10-28 01:00:55.301529+07:00\n","PROGRESS: [ 12093 / 12600 ]\n","{\n","  \"count\": 12093,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 28,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.14120472256674033,\n","  \"MSE_normalize\": 0.02040090385337576,\n","  \"RMSE_normalize\": 0.14283173265551238,\n","  \"MAPE_normalize\": 0.14800820495825767,\n","  \"MAE\": 6070.814732142857,\n","  \"MSE\": 37708998.97450474,\n","  \"RMSE\": 6140.76534110405,\n","  \"MAPE\": 0.0648099087023276\n","}\n","Percent CPU Usage: 52.5\n","Percent Ram Usage: 12.7\n","2022-10-28 01:01:09.810466+07:00\n","PROGRESS: [ 12094 / 12600 ]\n","{\n","  \"count\": 12094,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 64,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 24,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.13654830553749578,\n","  \"MSE_normalize\": 0.01926363689801752,\n","  \"RMSE_normalize\": 0.13879350452387,\n","  \"MAPE_normalize\": 0.1429836786907195,\n","  \"MAE\": 5870.620535714285,\n","  \"MSE\": 35606862.1831229,\n","  \"RMSE\": 5967.148580613935,\n","  \"MAPE\": 0.0626452639802642\n","}\n","Percent CPU Usage: 52.6\n","Percent Ram Usage: 12.7\n","2022-10-28 01:01:24.589147+07:00\n","PROGRESS: [ 12095 / 12600 ]\n","{\n","  \"count\": 12095,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 73,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.08116944274779676,\n","  \"MSE_normalize\": 0.006964347817542176,\n","  \"RMSE_normalize\": 0.08345266812716162,\n","  \"MAPE_normalize\": 0.0848336262323317,\n","  \"MAE\": 3489.715401785714,\n","  \"MSE\": 12872870.634495322,\n","  \"RMSE\": 3587.878291483049,\n","  \"MAPE\": 0.03720788119544799\n","}\n","Percent CPU Usage: 56.3\n","Percent Ram Usage: 12.7\n","2022-10-28 01:01:39.395016+07:00\n","PROGRESS: [ 12096 / 12600 ]\n","{\n","  \"count\": 12096,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 3,\n","  \"LSTM_hidden_units\": 32,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 128,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 23,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.10754911316340257,\n","  \"MSE_normalize\": 0.012154424698161899,\n","  \"RMSE_normalize\": 0.11024710743671191,\n","  \"MAPE_normalize\": 0.11245394913724484,\n","  \"MAE\": 4623.860491071428,\n","  \"MSE\": 22466229.04503522,\n","  \"RMSE\": 4739.855382291238,\n","  \"MAPE\": 0.04930983885769961\n","}\n","Percent CPU Usage: 52.4\n","Percent Ram Usage: 12.7\n","2022-10-28 01:01:54.273157+07:00\n","PROGRESS: [ 12097 / 12600 ]\n","{\n","  \"count\": 12097,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 64,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 30,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.0957190302019114,\n","  \"MSE_normalize\": 0.009485765906212014,\n","  \"RMSE_normalize\": 0.09739489671544405,\n","  \"MAPE_normalize\": 0.10021161175382454,\n","  \"MAE\": 4115.246651785715,\n","  \"MSE\": 17533456.173470628,\n","  \"RMSE\": 4187.297000867102,\n","  \"MAPE\": 0.04391014822739977\n","}\n","Percent CPU Usage: 66.4\n","Percent Ram Usage: 12.7\n","2022-10-28 01:02:00.712466+07:00\n","PROGRESS: [ 12098 / 12600 ]\n","{\n","  \"count\": 12098,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 64,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 2,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 29,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.07121957127584677,\n","  \"MSE_normalize\": 0.005498278531999592,\n","  \"RMSE_normalize\": 0.0741503778277602,\n","  \"MAPE_normalize\": 0.07430677778110002,\n","  \"MAE\": 3061.9430803571427,\n","  \"MSE\": 10163003.103210445,\n","  \"RMSE\": 3187.9465339322187,\n","  \"MAPE\": 0.03262249610907493\n","}\n","Percent CPU Usage: 57.5\n","Percent Ram Usage: 12.7\n","2022-10-28 01:02:10.754963+07:00\n","PROGRESS: [ 12099 / 12600 ]\n","{\n","  \"count\": 12099,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 64,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 40,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.06966286825329863,\n","  \"MSE_normalize\": 0.005225858989392048,\n","  \"RMSE_normalize\": 0.07229010298368684,\n","  \"MAPE_normalize\": 0.07271366128263759,\n","  \"MAE\": 2995.0145089285716,\n","  \"MSE\": 9659457.424307683,\n","  \"RMSE\": 3107.966766924589,\n","  \"MAPE\": 0.03191537102117298\n","}\n","Percent CPU Usage: 66.6\n","Percent Ram Usage: 12.7\n","2022-10-28 01:02:17.450336+07:00\n","PROGRESS: [ 12100 / 12600 ]\n","{\n","  \"count\": 12100,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"mul\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 64,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 4,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 37,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.0742660923945558,\n","  \"MSE_normalize\": 0.0059338416857325545,\n","  \"RMSE_normalize\": 0.07703143310190039,\n","  \"MAPE_normalize\": 0.07752306000832687,\n","  \"MAE\": 3192.9241071428573,\n","  \"MSE\": 10968115.099033896,\n","  \"RMSE\": 3311.814472314821,\n","  \"MAPE\": 0.03402518434692007\n","}\n","Percent CPU Usage: 64.8\n","Percent Ram Usage: 12.6\n","2022-10-28 01:02:24.719684+07:00\n","PROGRESS: [ 12101 / 12600 ]\n","{\n","  \"count\": 12101,\n","  \"model\": \"BiLSTM\",\n","  \"AHB_number\": \"AHB_12\",\n","  \"Multi_Uni\": \"uni\",\n","  \"n_layer\": 1,\n","  \"LSTM_hidden_units\": 64,\n","  \"dropouts\": 0.2,\n","  \"n_batch\": 8,\n","  \"n_steps\": 5,\n","  \"last_epoch\": 27,\n","  \"patience_list\": 10,\n","  \"MAE_normalize\": 0.07677025382055502,\n","  \"MSE_normalize\": 0.0062671648432851435,\n","  \"RMSE_normalize\": 0.07916542707069257,\n","  \"MAPE_normalize\": 0.08020097962396044,\n","  \"MAE\": 3300.5848214285716,\n","  \"MSE\": 11584222.992902478,\n","  \"RMSE\": 3403.560340717126,\n","  \"MAPE\": 0.035184692412606015\n","}\n","Percent CPU Usage: 59.9\n","Percent Ram Usage: 12.6\n","2022-10-28 01:02:29.955870+07:00\n","PROGRESS: [ 12102 / 12600 ]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","from numpy import array\n","from math import sqrt\n","from numpy import mean\n","from pandas import DataFrame\n","from pandas import concat\n","from pandas import read_csv\n","from keras.callbacks import EarlyStopping\n","from keras.models import Sequential\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n","from keras.preprocessing import sequence\n","from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Reshape\n","from pandas import read_csv\n","from keras import Model\n","from keras.layers import Layer\n","import keras.backend as K\n","from keras.layers import Input, SimpleRNN\n","import json\n","import psutil \n","from datetime import datetime, timezone, timedelta\n","\n","\n","\n","file_list = os.listdir('ThaiDepression')\n","file_list.sort()\n","df_list = []\n","for i in range(14):\n","    df_list.append(pd.read_csv('ThaiDepression/' + file_list[i], index_col=0))\n","\n","\n","\n","# split a univariate sequence into samples\n","def uni_split_sequence(sequence, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the sequence\n","        if end_ix > len(sequence)-1:\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","\n","    # split a multivariate sequence into samples\n","def multi_split_sequences(sequences, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequences)):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        # check if we are beyond the dataset\n","        if end_ix > len(sequences):\n","            break\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","\n","def get_scaler(scaler):\n","    scalers = {\n","        \"minmax\": MinMaxScaler,\n","        \"standard\": StandardScaler,\n","        \"maxabs\": MaxAbsScaler,\n","        \"robust\": RobustScaler,\n","    }\n","    return scalers.get(scaler.lower())()\n","\n","\n","# Add attention layer to the deep learning network\n","class attention(Layer):\n","    def __init__(self,**kwargs):\n","        super(attention,self).__init__(**kwargs)\n"," \n","    def build(self,input_shape):\n","        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n","                               initializer='random_normal', trainable=True)\n","        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n","                               initializer='zeros', trainable=True)        \n","        super(attention, self).build(input_shape)\n"," \n","    def call(self,x):\n","        # Alignment scores. Pass them through tanh function\n","        e = K.tanh(K.dot(x,self.W)+self.b)\n","        # Remove dimension of size 1\n","        e = K.squeeze(e, axis=-1)   \n","        # Compute the weights\n","        alpha = K.softmax(e)\n","        # Reshape to tensorFlow format\n","        alpha = K.expand_dims(alpha, axis=-1)\n","        # Compute the context vector\n","        context = x * alpha\n","        context = K.sum(context, axis=1)\n","        return context\n","\n","\n","\n","%matplotlib inline\n","# define scope of configs\n","AHB_list = [11]\n","BiLSTM_hidden_units = [8, 16, 32, 64, 128]\n","n_layer = [1, 2, 3]\n","n_batch = [2, 4, 8, 16, 32, 64, 128]\n","n_steps = [1, 2, 3, 4, 5]\n","patience_list = [3, 5, 7, 10]\n","mul_uni = ['uni','mul']\n","dropouts = [0.2, 0.3, 0.5]\n","count_start = 12051\n","\n","\n","timezone_offset = 7.0  # Bangkok Time (UTC+07:00)\n","tzinfo = timezone(timedelta(hours=timezone_offset))\n","count = 0\n","performance_json = []\n","for g in AHB_list:\n","    for h in patience_list:\n","        for a in n_steps:\n","            for b in dropouts:\n","                for c in BiLSTM_hidden_units:\n","                    for d in n_layer:\n","                        for e in n_batch:\n","                            for f in mul_uni:\n","                                \n","                                count = count + 1 \n","                                \n","                                if count < count_start:\n","                                    continue\n","\n","                                print('PROGRESS: [ ' + str(count) + ' / ' + str(len(dropouts)*len(AHB_list)*len(n_steps)*len(BiLSTM_hidden_units)*len(n_layer)*len(n_batch)*len(patience_list)*len(mul_uni)) + ' ]')\n","                                \n","                                if f == 'uni':\n","                                    if g == 13:\n","                                        raw_seq = list(df_list[g]['Country_Level'])\n","                                        ahb = 'Country_Level'\n","                                    else:    \n","                                        raw_seq = list(df_list[g]['AHB_'+str(g+1)])\n","                                        ahb = 'AHB_'+str(g+1)\n","                                    n_features = 1\n","                                    scaler = get_scaler('minmax')\n","                                    raw_seq_arr = scaler.fit_transform(np.array(raw_seq).reshape(len(raw_seq),-1))\n","                                    X, y = uni_split_sequence(raw_seq_arr, a)\n","                                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.9, shuffle=False, stratify=None)\n","                                    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n","                                    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n","                                if f == 'mul':\n","                                    if g == 13:\n","                                        raw_seq = list(df_list[13].drop(df_list[13].columns[:77], axis=1).values)\n","                                        ahb = 'Country_Level'\n","                                        scaler_y = get_scaler('minmax')\n","                                        scaler_y.fit(np.array(df_list[13]['Country_Level']).reshape(len(df_list[13]['Country_Level']),-1))\n","                                    else:    \n","                                        raw_seq = list(df_list[g].drop(['Country_Level'], axis=1).values)\n","                                        ahb = 'AHB_'+str(g+1)\n","                                        scaler_y = get_scaler('minmax')\n","                                        scaler_y.fit(np.array(df_list[g]['AHB_'+str(g+1)]).reshape(len(df_list[13]['AHB_'+str(g+1)]),-1))\n","                                    n_features = len(raw_seq[0])-1\n","                                    scaler = get_scaler('minmax')\n","                                    raw_seq_arr = scaler.fit_transform(np.array(raw_seq))\n","                                    X, y = multi_split_sequences(raw_seq_arr, a)\n","                                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.9, shuffle=False, stratify=None)\n","                                    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n","                                    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n","\n","                                callback = EarlyStopping(monitor='loss', patience=h)\n","                                x=Input(shape=(a,n_features))\n","                                if d == 1:\n","                                    BiLSTM_layer = Bidirectional(LSTM(units=c, return_sequences=True, input_shape=(a,n_features), activation='tanh', dropout=b))(x)\n","                                    attention_layer = attention()(BiLSTM_layer)\n","                                if d == 2:\n","                                    BiLSTM_layer = Bidirectional(LSTM(units=c, return_sequences=True, input_shape=(a,n_features), activation='tanh', dropout=b))(x)\n","                                    BiLSTM_layer2 = Bidirectional(LSTM(units=c, return_sequences=True, activation='tanh', dropout=b))(BiLSTM_layer)\n","                                    attention_layer = attention()(BiLSTM_layer2)\n","                                if d ==3:\n","                                    BiLSTM_layer = Bidirectional(LSTM(units=c, return_sequences=True, input_shape=(a,n_features), activation='tanh', dropout=b))(x)\n","                                    BiLSTM_layer2 = Bidirectional(LSTM(units=c, return_sequences=True, activation='tanh', dropout=b))(BiLSTM_layer)\n","                                    BiLSTM_layer3 = Bidirectional(LSTM(units=c, return_sequences=True, activation='tanh', dropout=b))(BiLSTM_layer2)\n","                                    attention_layer = attention()(BiLSTM_layer3)\n","                                outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n","                                model=Model(x,outputs)\n","                                model.compile(loss='mse', optimizer='adam')  \n","                                history = model.fit(X_train, y_train, epochs=2000, batch_size=e, verbose=0, callbacks=[callback])\n","                                last_epoch = len(history.history['loss']) \n","\n","\n","                                yhat = model.predict(X_test, verbose=0)\n","                                mae = mean_absolute_error(y_test, yhat)\n","                                mse = mean_squared_error(y_test, yhat)\n","                                rmse = mean_squared_error(y_test, yhat, squared = False)\n","                                mape = mean_absolute_percentage_error(y_test, yhat)\n","\n","                                yhat = model.predict(X_test, verbose=0)\n","                                yhat = yhat.reshape(yhat.shape[0],-1)\n","                                mae = mean_absolute_error(y_test, yhat)\n","                                mse = mean_squared_error(y_test, yhat)\n","                                rmse = mean_squared_error(y_test, yhat, squared = False)\n","                                mape = mean_absolute_percentage_error(y_test, yhat)\n","                                \n","                                if f == 'uni':\n","                                    yhat_inverse = scaler.inverse_transform(yhat)\n","                                    y_test_inverse = scaler.inverse_transform(y_test)\n","                                if f == 'mul':\n","                                    yhat_inverse = scaler_y.inverse_transform(yhat)\n","                                    y_test_inverse = scaler_y.inverse_transform(y_test.reshape(len(y_test),-1))\n","\n","\n","                                mae_inverse = mean_absolute_error(y_test_inverse, yhat_inverse)\n","                                mse_inverse = mean_squared_error(y_test_inverse, yhat_inverse)\n","                                rmse_inverse = mean_squared_error(y_test_inverse, yhat_inverse, squared = False)\n","                                mape_inverse = mean_absolute_percentage_error(y_test_inverse, yhat_inverse)\n","\n","                                performance_json.append({'count': count,'model': 'BiLSTM', 'AHB_number': ahb, 'Multi_Uni': f, \\\n","                                                         'n_layer': d, 'LSTM_hidden_units': c, 'dropouts': b,'n_batch': e,\\\n","                                                         'n_steps': a, 'last_epoch': last_epoch, 'patience_list': h, 'MAE_normalize': float(mae), \\\n","                                                         'MSE_normalize': float(mse), 'RMSE_normalize': float(rmse), 'MAPE_normalize': float(mape), \\\n","                                                         'MAE': float(mae_inverse), 'MSE': float(mse_inverse), 'RMSE': float(rmse_inverse), 'MAPE': float(mape_inverse)})\n","                                \n","                                if count % 25 == 0:\n","                                    performance_name = \"loop_performance_BiLSTM_with_Attention_AHB12_s\"\n","                                    json.dump(performance_json, open(performance_name + \".json\",\"w\"))\n","                                    performance_df = pd.read_json(performance_name + \".json\")\n","                                    performance_df.to_csv(performance_name + \".csv\", index=False)\n","                                json_formatted_str = json.dumps(performance_json[-1], indent=2)\n","                                print(json_formatted_str)\n","                                print('Percent CPU Usage: ' + str(psutil.cpu_percent()))\n","                                print('Percent Ram Usage: ' + str(psutil.virtual_memory()[2]))\n","                                print(datetime.now(tzinfo))\n","\n","                                \n","                                \n","                                \n","name = \"all_performance_BiLSTM_with_Attention_AHB12\"\n","json.dump(performance_json, open(name + \".json\",\"w\"))\n","df_json = pd.read_json(name + '.json')\n","df_json.to_csv(name + '.csv', index=False)"]}]}